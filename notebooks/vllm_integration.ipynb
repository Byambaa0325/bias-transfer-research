{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# vLLM Integration for Bias Transfer Research\n",
        "\n",
        "This notebook demonstrates how to use vLLM (self-hosted LLM inference server) for model evaluation in bias transfer research.\n",
        "\n",
        "## ⚠️ **IMPORTANT: Platform Compatibility**\n",
        "\n",
        "**vLLM only supports Linux and macOS. It does NOT support Windows natively.**\n",
        "\n",
        "### Windows Users - Your Options:\n",
        "\n",
        "1. **WSL2 (Recommended)**: Use Windows Subsystem for Linux 2\n",
        "   - Install WSL2: `wsl --install` (in PowerShell as Administrator)\n",
        "   - Install CUDA in WSL2\n",
        "   - Run vLLM inside WSL2\n",
        "   - Connect from Windows using `http://localhost:8000/v1`\n",
        "\n",
        "2. **Ollama (Easier Alternative)**: Better Windows support\n",
        "   - Native Windows installation\n",
        "   - See `ollama_integration.ipynb` for Ollama setup (if available)\n",
        "   - Easier to get started on Windows\n",
        "\n",
        "3. **Docker with WSL2**: Run vLLM in Docker container\n",
        "   - Requires Docker Desktop with WSL2 backend\n",
        "\n",
        "## Overview\n",
        "\n",
        "vLLM is a high-performance inference engine for LLMs that provides:\n",
        "- Fast inference with PagedAttention\n",
        "- Efficient GPU memory usage\n",
        "- OpenAI-compatible API\n",
        "- Support for quantized models (4-bit, 8-bit)\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. **Hardware**: NVIDIA GPU with CUDA support (RTX 4060 recommended)\n",
        "2. **Software**: \n",
        "   - **Linux/macOS**: Python 3.8+, CUDA toolkit, vLLM installed\n",
        "   - **Windows**: WSL2 with CUDA support OR use Ollama instead\n",
        "3. **Models**: HuggingFace model IDs (e.g., `meta-llama/Llama-3.1-8B-Instruct`)\n",
        "\n",
        "## Setup Steps\n",
        "\n",
        "### For Linux/macOS:\n",
        "1. Install vLLM: `pip install vllm`\n",
        "2. Start vLLM server: `python -m vllm.entrypoints.openai.api_server --model <model_id>`\n",
        "3. Use this notebook to evaluate models\n",
        "\n",
        "### For Windows (WSL2):\n",
        "1. Install WSL2: `wsl --install` (in PowerShell as Administrator, restart after)\n",
        "2. Install CUDA in WSL2 (download from NVIDIA website)\n",
        "3. Install vLLM in WSL2: `pip install vllm` (inside WSL2 terminal)\n",
        "4. Start vLLM server in WSL2\n",
        "5. Connect from Windows using `http://localhost:8000/v1` (WSL2 exposes ports automatically)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vllm\n",
            "  Downloading vllm-0.12.0.tar.gz (17.6 MB)\n",
            "     ---------------------------------------- 0.0/17.6 MB ? eta -:--:--\n",
            "     --- ------------------------------------ 1.6/17.6 MB 27.9 MB/s eta 0:00:01\n",
            "     ----------------- ---------------------- 7.6/17.6 MB 29.4 MB/s eta 0:00:01\n",
            "     ------------------------------ -------- 13.6/17.6 MB 29.5 MB/s eta 0:00:01\n",
            "     --------------------------------------  17.6/17.6 MB 29.1 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 17.6/17.6 MB 25.2 MB/s  0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: regex in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (2025.11.3)\n",
            "Collecting cachetools (from vllm)\n",
            "  Using cached cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: psutil in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (7.1.3)\n",
            "Collecting sentencepiece (from vllm)\n",
            "  Downloading sentencepiece-0.2.1-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (2.3.5)\n",
            "Requirement already satisfied: requests>=2.26.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (2.32.5)\n",
            "Requirement already satisfied: tqdm in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (4.67.1)\n",
            "Collecting blake3 (from vllm)\n",
            "  Downloading blake3-1.0.8-cp311-cp311-win_amd64.whl.metadata (4.7 kB)\n",
            "Collecting py-cpuinfo (from vllm)\n",
            "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
            "Requirement already satisfied: transformers<5,>=4.56.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (4.57.3)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (0.22.1)\n",
            "Collecting protobuf (from vllm)\n",
            "  Downloading protobuf-6.33.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
            "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi-0.124.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting aiohttp (from vllm)\n",
            "  Downloading aiohttp-3.13.2-cp311-cp311-win_amd64.whl.metadata (8.4 kB)\n",
            "Collecting openai>=1.99.1 (from vllm)\n",
            "  Downloading openai-2.9.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting pydantic>=2.12.0 (from vllm)\n",
            "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (0.23.1)\n",
            "Requirement already satisfied: pillow in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (12.0.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken>=0.6.0 (from vllm)\n",
            "  Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting lm-format-enforcer==0.11.3 (from vllm)\n",
            "  Downloading lm_format_enforcer-0.11.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting outlines_core==0.2.11 (from vllm)\n",
            "  Downloading outlines_core-0.2.11-cp311-cp311-win_amd64.whl.metadata (6.0 kB)\n",
            "Collecting diskcache==5.6.3 (from vllm)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (4.15.0)\n",
            "Requirement already satisfied: filelock>=3.16.1 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (3.20.0)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Downloading partial_json_parser-0.2.1.1.post7-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (27.1.0)\n",
            "Collecting msgspec (from vllm)\n",
            "  Downloading msgspec-0.20.0-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
            "Collecting gguf>=0.17.0 (from vllm)\n",
            "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting mistral_common>=1.8.5 (from mistral_common[image]>=1.8.5->vllm)\n",
            "  Downloading mistral_common-1.8.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencv-python-headless>=4.11.0 (from vllm)\n",
            "  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pyyaml in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (6.0.3)\n",
            "Collecting einops (from vllm)\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting compressed-tensors==0.12.2 (from vllm)\n",
            "  Downloading compressed_tensors-0.12.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting depyf==0.20.0 (from vllm)\n",
            "  Downloading depyf-0.20.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting cloudpickle (from vllm)\n",
            "  Using cached cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting watchfiles (from vllm)\n",
            "  Downloading watchfiles-1.1.1-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: python-json-logger in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (4.0.0)\n",
            "Requirement already satisfied: scipy in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from vllm) (1.16.3)\n",
            "Collecting ninja (from vllm)\n",
            "  Using cached ninja-1.13.0-py3-none-win_amd64.whl.metadata (5.1 kB)\n",
            "Collecting pybase64 (from vllm)\n",
            "  Downloading pybase64-1.4.3-cp311-cp311-win_amd64.whl.metadata (9.1 kB)\n",
            "Collecting cbor2 (from vllm)\n",
            "  Downloading cbor2-5.7.1-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
            "Collecting setproctitle (from vllm)\n",
            "  Downloading setproctitle-1.3.7-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
            "Collecting openai-harmony>=0.0.3 (from vllm)\n",
            "  Downloading openai_harmony-0.0.8-cp38-abi3-win_amd64.whl.metadata (8.2 kB)\n",
            "Collecting anthropic==0.71.0 (from vllm)\n",
            "  Using cached anthropic-0.71.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting model-hosting-container-standards<1.0.0,>=0.1.9 (from vllm)\n",
            "  Downloading model_hosting_container_standards-0.1.10-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from anthropic==0.71.0->vllm) (4.12.0)\n",
            "Collecting distro<2,>=1.7.0 (from anthropic==0.71.0->vllm)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting docstring-parser<1,>=0.15 (from anthropic==0.71.0->vllm)\n",
            "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from anthropic==0.71.0->vllm) (0.28.1)\n",
            "Collecting jiter<1,>=0.4.0 (from anthropic==0.71.0->vllm)\n",
            "  Downloading jiter-0.12.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
            "Collecting sniffio (from anthropic==0.71.0->vllm)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from compressed-tensors==0.12.2->vllm) (2.9.1)\n",
            "Collecting loguru (from compressed-tensors==0.12.2->vllm)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting astor (from depyf==0.20.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting dill (from depyf==0.20.0->vllm)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.11.3->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from lm-format-enforcer==0.11.3->vllm) (25.0)\n",
            "Requirement already satisfied: idna>=2.8 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic==0.71.0->vllm) (3.11)\n",
            "Requirement already satisfied: certifi in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (0.16.0)\n",
            "Collecting jmespath (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm)\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: setuptools in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm) (80.9.0)\n",
            "Collecting starlette>=0.49.1 (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm)\n",
            "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting supervisor>=4.2.0 (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm)\n",
            "  Downloading supervisor-4.3.0-py2.py3-none-any.whl.metadata (87 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.12.0->vllm)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic>=2.12.0->vllm)\n",
            "  Using cached pydantic_core-2.41.5-cp311-cp311-win_amd64.whl.metadata (7.4 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic>=2.12.0->vllm)\n",
            "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from transformers<5,>=4.56.0->vllm) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from transformers<5,>=4.56.0->vllm) (0.7.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5,>=4.56.0->vllm) (2025.12.0)\n",
            "Collecting annotated-doc>=0.0.2 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cli-0.0.16-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: jinja2>=3.1.5 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from fastapi[standard]>=0.115.0->vllm) (3.1.6)\n",
            "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting typer>=0.15.1 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rich_toolkit-0.17.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cloud_cli-0.6.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rignore-0.7.6-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
            "Collecting sentry-sdk>=2.20.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading sentry_sdk-2.47.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fastar>=0.8.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastar-0.8.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from jinja2>=3.1.5->fastapi[standard]>=0.115.0->vllm) (3.0.3)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (4.25.1)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)\n",
            "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (0.30.0)\n",
            "Collecting numpy (from vllm)\n",
            "  Using cached numpy-2.2.6-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from requests>=2.26.0->vllm) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from requests>=2.26.0->vllm) (2.6.0)\n",
            "Collecting click>=8.1.7 (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting rich>=13.7.1 (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: colorama in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from click>=8.1.7->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.4.6)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sympy>=1.13.3 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from torch>=1.7.0->compressed-tensors==0.12.2->vllm) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from torch>=1.7.0->compressed-tensors==0.12.2->vllm) (3.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from sympy>=1.13.3->torch>=1.7.0->compressed-tensors==0.12.2->vllm) (1.3.0)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading httptools-0.7.1-cp311-cp311-win_amd64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in e:\\ucl-workspaces\\bias-transfer-research\\.conda\\lib\\site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.2.1)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->vllm)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp->vllm)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->vllm)\n",
            "  Downloading frozenlist-1.8.0-cp311-cp311-win_amd64.whl.metadata (21 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->vllm)\n",
            "  Downloading multidict-6.7.0-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->vllm)\n",
            "  Downloading propcache-0.4.1-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->vllm)\n",
            "  Downloading yarl-1.22.0-cp311-cp311-win_amd64.whl.metadata (77 kB)\n",
            "Collecting win32-setctime>=1.0.0 (from loguru->compressed-tensors==0.12.2->vllm)\n",
            "  Downloading win32_setctime-1.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Using cached anthropic-0.71.0-py3-none-any.whl (355 kB)\n",
            "Downloading compressed_tensors-0.12.2-py3-none-any.whl (183 kB)\n",
            "Downloading depyf-0.20.0-py3-none-any.whl (39 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "Downloading lm_format_enforcer-0.11.3-py3-none-any.whl (45 kB)\n",
            "Downloading outlines_core-0.2.11-cp311-cp311-win_amd64.whl (2.1 MB)\n",
            "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.1/2.1 MB 23.1 MB/s  0:00:00\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
            "Downloading jiter-0.12.0-cp311-cp311-win_amd64.whl (204 kB)\n",
            "Downloading model_hosting_container_standards-0.1.10-py3-none-any.whl (104 kB)\n",
            "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "Using cached pydantic_core-2.41.5-cp311-cp311-win_amd64.whl (2.0 MB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading fastapi-0.124.0-py3-none-any.whl (112 kB)\n",
            "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
            "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
            "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "Downloading fastapi_cli-0.0.16-py3-none-any.whl (12 kB)\n",
            "Downloading fastapi_cloud_cli-0.6.0-py3-none-any.whl (23 kB)\n",
            "Downloading fastar-0.8.0-cp311-cp311-win_amd64.whl (490 kB)\n",
            "Downloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
            "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading mistral_common-1.8.6-py3-none-any.whl (6.5 MB)\n",
            "   ---------------------------------------- 0.0/6.5 MB ? eta -:--:--\n",
            "   ------------------------------------- -- 6.0/6.5 MB 30.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.5/6.5 MB 22.3 MB/s  0:00:00\n",
            "Downloading openai-2.9.0-py3-none-any.whl (1.0 MB)\n",
            "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.0/1.0 MB 12.4 MB/s  0:00:00\n",
            "Downloading openai_harmony-0.0.8-cp38-abi3-win_amd64.whl (2.4 MB)\n",
            "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.4/2.4 MB 14.0 MB/s  0:00:00\n",
            "Using cached opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl (38.9 MB)\n",
            "Using cached numpy-2.2.6-cp311-cp311-win_amd64.whl (12.9 MB)\n",
            "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
            "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
            "   ------------------------------------ --- 5.8/6.3 MB 29.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.3/6.3 MB 19.5 MB/s  0:00:00\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading rich_toolkit-0.17.0-py3-none-any.whl (31 kB)\n",
            "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
            "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
            "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading rignore-0.7.6-cp311-cp311-win_amd64.whl (727 kB)\n",
            "   ---------------------------------------- 0.0/727.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 727.1/727.1 kB 9.9 MB/s  0:00:00\n",
            "Downloading sentry_sdk-2.47.0-py2.py3-none-any.whl (411 kB)\n",
            "Downloading supervisor-4.3.0-py2.py3-none-any.whl (320 kB)\n",
            "Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl (879 kB)\n",
            "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 879.4/879.4 kB 7.9 MB/s  0:00:00\n",
            "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
            "Downloading httptools-0.7.1-cp311-cp311-win_amd64.whl (86 kB)\n",
            "Downloading watchfiles-1.1.1-cp311-cp311-win_amd64.whl (287 kB)\n",
            "Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
            "Downloading aiohttp-3.13.2-cp311-cp311-win_amd64.whl (456 kB)\n",
            "Downloading multidict-6.7.0-cp311-cp311-win_amd64.whl (46 kB)\n",
            "Downloading yarl-1.22.0-cp311-cp311-win_amd64.whl (86 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading frozenlist-1.8.0-cp311-cp311-win_amd64.whl (44 kB)\n",
            "Downloading propcache-0.4.1-cp311-cp311-win_amd64.whl (41 kB)\n",
            "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading blake3-1.0.8-cp311-cp311-win_amd64.whl (215 kB)\n",
            "Using cached cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading cbor2-5.7.1-cp311-cp311-win_amd64.whl (68 kB)\n",
            "Using cached cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
            "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "Downloading win32_setctime-1.2.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading msgspec-0.20.0-cp311-cp311-win_amd64.whl (188 kB)\n",
            "Using cached ninja-1.13.0-py3-none-win_amd64.whl (309 kB)\n",
            "Downloading partial_json_parser-0.2.1.1.post7-py3-none-any.whl (10 kB)\n",
            "Downloading protobuf-6.33.2-cp310-abi3-win_amd64.whl (436 kB)\n",
            "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Downloading pybase64-1.4.3-cp311-cp311-win_amd64.whl (35 kB)\n",
            "Downloading sentencepiece-0.2.1-cp311-cp311-win_amd64.whl (1.1 MB)\n",
            "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.1/1.1 MB 10.2 MB/s  0:00:00\n",
            "Downloading setproctitle-1.3.7-cp311-cp311-win_amd64.whl (13 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: vllm\n",
            "  Building wheel for vllm (pyproject.toml): started\n",
            "  Building wheel for vllm (pyproject.toml): finished with status 'error'\n",
            "Failed to build vllm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Building wheel for vllm (pyproject.toml) did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [2578 lines of output]\n",
            "      C:\\Users\\byamb\\AppData\\Local\\Temp\\pip-build-env-a3avsgi5\\overlay\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:279: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
            "        cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
            "      vLLM only supports Linux platform (including WSL) and MacOS.Building on win32, so vLLM may not be able to run correctly\n",
            "      C:\\Users\\byamb\\AppData\\Local\\Temp\\pip-build-env-a3avsgi5\\overlay\\Lib\\site-packages\\setuptools_scm\\_integration\\version_inference.py:51: UserWarning: version of None already set\n",
            "        warnings.warn(self.message)\n",
            "      running bdist_wheel\n",
            "      running build\n",
            "      running build_py\n",
            "      creating build\\lib\\vllm\n",
            "      copying vllm\\beam_search.py -> build\\lib\\vllm\n",
            "      copying vllm\\collect_env.py -> build\\lib\\vllm\n",
            "      copying vllm\\connections.py -> build\\lib\\vllm\n",
            "      copying vllm\\envs.py -> build\\lib\\vllm\n",
            "      copying vllm\\env_override.py -> build\\lib\\vllm\n",
            "      copying vllm\\forward_context.py -> build\\lib\\vllm\n",
            "      copying vllm\\logger.py -> build\\lib\\vllm\n",
            "      copying vllm\\logits_process.py -> build\\lib\\vllm\n",
            "      copying vllm\\logprobs.py -> build\\lib\\vllm\n",
            "      copying vllm\\outputs.py -> build\\lib\\vllm\n",
            "      copying vllm\\pooling_params.py -> build\\lib\\vllm\n",
            "      copying vllm\\sampling_params.py -> build\\lib\\vllm\n",
            "      copying vllm\\scalar_type.py -> build\\lib\\vllm\n",
            "      copying vllm\\scripts.py -> build\\lib\\vllm\n",
            "      copying vllm\\sequence.py -> build\\lib\\vllm\n",
            "      copying vllm\\tasks.py -> build\\lib\\vllm\n",
            "      copying vllm\\tracing.py -> build\\lib\\vllm\n",
            "      copying vllm\\version.py -> build\\lib\\vllm\n",
            "      copying vllm\\_aiter_ops.py -> build\\lib\\vllm\n",
            "      copying vllm\\_bc_linter.py -> build\\lib\\vllm\n",
            "      copying vllm\\_custom_ops.py -> build\\lib\\vllm\n",
            "      copying vllm\\_ipex_ops.py -> build\\lib\\vllm\n",
            "      copying vllm\\_version.py -> build\\lib\\vllm\n",
            "      copying vllm\\__init__.py -> build\\lib\\vllm\n",
            "      creating build\\lib\\vllm\\assets\n",
            "      copying vllm\\assets\\audio.py -> build\\lib\\vllm\\assets\n",
            "      copying vllm\\assets\\base.py -> build\\lib\\vllm\\assets\n",
            "      copying vllm\\assets\\image.py -> build\\lib\\vllm\\assets\n",
            "      copying vllm\\assets\\video.py -> build\\lib\\vllm\\assets\n",
            "      copying vllm\\assets\\__init__.py -> build\\lib\\vllm\\assets\n",
            "      creating build\\lib\\vllm\\attention\n",
            "      copying vllm\\attention\\layer.py -> build\\lib\\vllm\\attention\n",
            "      copying vllm\\attention\\selector.py -> build\\lib\\vllm\\attention\n",
            "      copying vllm\\attention\\__init__.py -> build\\lib\\vllm\\attention\n",
            "      creating build\\lib\\vllm\\benchmarks\n",
            "      copying vllm\\benchmarks\\datasets.py -> build\\lib\\vllm\\benchmarks\n",
            "      copying vllm\\benchmarks\\latency.py -> build\\lib\\vllm\\benchmarks\n",
            "      copying vllm\\benchmarks\\serve.py -> build\\lib\\vllm\\benchmarks\n",
            "      copying vllm\\benchmarks\\throughput.py -> build\\lib\\vllm\\benchmarks\n",
            "      copying vllm\\benchmarks\\__init__.py -> build\\lib\\vllm\\benchmarks\n",
            "      creating build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\activation_quant_fusion.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\backends.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\base_static_graph.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\caching.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\collective_fusion.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\compiler_interface.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\counter.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\cuda_graph.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\decorators.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\fix_functionalization.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\fusion.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\fusion_attn.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\fx_utils.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\inductor_pass.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\matcher_utils.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\monitor.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\noop_elimination.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\partition_rules.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\pass_manager.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\piecewise_backend.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\post_cleanup.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\qk_norm_rope_fusion.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\sequence_parallelism.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\torch25_custom_graph_pass.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\vllm_inductor_pass.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\wrapper.py -> build\\lib\\vllm\\compilation\n",
            "      copying vllm\\compilation\\__init__.py -> build\\lib\\vllm\\compilation\n",
            "      creating build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\cache.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\compilation.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\device.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\ec_transfer.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\kv_events.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\kv_transfer.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\load.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\lora.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\model.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\multimodal.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\observability.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\parallel.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\pooler.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\scheduler.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\speculative.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\speech_to_text.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\structured_outputs.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\utils.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\vllm.py -> build\\lib\\vllm\\config\n",
            "      copying vllm\\config\\__init__.py -> build\\lib\\vllm\\config\n",
            "      creating build\\lib\\vllm\\device_allocator\n",
            "      copying vllm\\device_allocator\\cumem.py -> build\\lib\\vllm\\device_allocator\n",
            "      copying vllm\\device_allocator\\__init__.py -> build\\lib\\vllm\\device_allocator\n",
            "      creating build\\lib\\vllm\\distributed\n",
            "      copying vllm\\distributed\\communication_op.py -> build\\lib\\vllm\\distributed\n",
            "      copying vllm\\distributed\\kv_events.py -> build\\lib\\vllm\\distributed\n",
            "      copying vllm\\distributed\\parallel_state.py -> build\\lib\\vllm\\distributed\n",
            "      copying vllm\\distributed\\tpu_distributed_utils.py -> build\\lib\\vllm\\distributed\n",
            "      copying vllm\\distributed\\utils.py -> build\\lib\\vllm\\distributed\n",
            "      copying vllm\\distributed\\__init__.py -> build\\lib\\vllm\\distributed\n",
            "      creating build\\lib\\vllm\\engine\n",
            "      copying vllm\\engine\\arg_utils.py -> build\\lib\\vllm\\engine\n",
            "      copying vllm\\engine\\async_llm_engine.py -> build\\lib\\vllm\\engine\n",
            "      copying vllm\\engine\\llm_engine.py -> build\\lib\\vllm\\engine\n",
            "      copying vllm\\engine\\protocol.py -> build\\lib\\vllm\\engine\n",
            "      copying vllm\\engine\\__init__.py -> build\\lib\\vllm\\engine\n",
            "      creating build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\api_server.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\chat_utils.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\constants.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\context.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\dynamic_lora.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\harmony_utils.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\launcher.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\llm.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\logger.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\renderer.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\responses_utils.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\score_utils.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\ssl.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\tool.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\tool_server.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\utils.py -> build\\lib\\vllm\\entrypoints\n",
            "      copying vllm\\entrypoints\\__init__.py -> build\\lib\\vllm\\entrypoints\n",
            "      creating build\\lib\\vllm\\inputs\n",
            "      copying vllm\\inputs\\data.py -> build\\lib\\vllm\\inputs\n",
            "      copying vllm\\inputs\\parse.py -> build\\lib\\vllm\\inputs\n",
            "      copying vllm\\inputs\\preprocess.py -> build\\lib\\vllm\\inputs\n",
            "      copying vllm\\inputs\\__init__.py -> build\\lib\\vllm\\inputs\n",
            "      creating build\\lib\\vllm\\logging_utils\n",
            "      copying vllm\\logging_utils\\dump_input.py -> build\\lib\\vllm\\logging_utils\n",
            "      copying vllm\\logging_utils\\formatter.py -> build\\lib\\vllm\\logging_utils\n",
            "      copying vllm\\logging_utils\\lazy.py -> build\\lib\\vllm\\logging_utils\n",
            "      copying vllm\\logging_utils\\log_time.py -> build\\lib\\vllm\\logging_utils\n",
            "      copying vllm\\logging_utils\\__init__.py -> build\\lib\\vllm\\logging_utils\n",
            "      creating build\\lib\\vllm\\lora\n",
            "      copying vllm\\lora\\lora_weights.py -> build\\lib\\vllm\\lora\n",
            "      copying vllm\\lora\\models.py -> build\\lib\\vllm\\lora\n",
            "      copying vllm\\lora\\peft_helper.py -> build\\lib\\vllm\\lora\n",
            "      copying vllm\\lora\\request.py -> build\\lib\\vllm\\lora\n",
            "      copying vllm\\lora\\resolver.py -> build\\lib\\vllm\\lora\n",
            "      copying vllm\\lora\\utils.py -> build\\lib\\vllm\\lora\n",
            "      copying vllm\\lora\\worker_manager.py -> build\\lib\\vllm\\lora\n",
            "      copying vllm\\lora\\__init__.py -> build\\lib\\vllm\\lora\n",
            "      creating build\\lib\\vllm\\model_executor\n",
            "      copying vllm\\model_executor\\custom_op.py -> build\\lib\\vllm\\model_executor\n",
            "      copying vllm\\model_executor\\parameter.py -> build\\lib\\vllm\\model_executor\n",
            "      copying vllm\\model_executor\\utils.py -> build\\lib\\vllm\\model_executor\n",
            "      copying vllm\\model_executor\\__init__.py -> build\\lib\\vllm\\model_executor\n",
            "      creating build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\audio.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\base.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\cache.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\evs.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\hasher.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\image.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\inputs.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\parse.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\processing.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\profiling.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\registry.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\utils.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\video.py -> build\\lib\\vllm\\multimodal\n",
            "      copying vllm\\multimodal\\__init__.py -> build\\lib\\vllm\\multimodal\n",
            "      creating build\\lib\\vllm\\platforms\n",
            "      copying vllm\\platforms\\cpu.py -> build\\lib\\vllm\\platforms\n",
            "      copying vllm\\platforms\\cuda.py -> build\\lib\\vllm\\platforms\n",
            "      copying vllm\\platforms\\interface.py -> build\\lib\\vllm\\platforms\n",
            "      copying vllm\\platforms\\rocm.py -> build\\lib\\vllm\\platforms\n",
            "      copying vllm\\platforms\\tpu.py -> build\\lib\\vllm\\platforms\n",
            "      copying vllm\\platforms\\xpu.py -> build\\lib\\vllm\\platforms\n",
            "      copying vllm\\platforms\\__init__.py -> build\\lib\\vllm\\platforms\n",
            "      creating build\\lib\\vllm\\plugins\n",
            "      copying vllm\\plugins\\__init__.py -> build\\lib\\vllm\\plugins\n",
            "      creating build\\lib\\vllm\\profiler\n",
            "      copying vllm\\profiler\\gpu_profiler.py -> build\\lib\\vllm\\profiler\n",
            "      copying vllm\\profiler\\layerwise_profile.py -> build\\lib\\vllm\\profiler\n",
            "      copying vllm\\profiler\\utils.py -> build\\lib\\vllm\\profiler\n",
            "      copying vllm\\profiler\\__init__.py -> build\\lib\\vllm\\profiler\n",
            "      creating build\\lib\\vllm\\ray\n",
            "      copying vllm\\ray\\lazy_utils.py -> build\\lib\\vllm\\ray\n",
            "      copying vllm\\ray\\ray_env.py -> build\\lib\\vllm\\ray\n",
            "      copying vllm\\ray\\__init__.py -> build\\lib\\vllm\\ray\n",
            "      creating build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\abs_reasoning_parsers.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\basic_parsers.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\deepseek_r1_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\deepseek_v3_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\ernie45_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\glm4_moe_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\gptoss_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\granite_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\hunyuan_a13b_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\identity_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\minimax_m2_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\mistral_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\olmo3_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\qwen3_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\seedoss_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\step3_reasoning_parser.py -> build\\lib\\vllm\\reasoning\n",
            "      copying vllm\\reasoning\\__init__.py -> build\\lib\\vllm\\reasoning\n",
            "      creating build\\lib\\vllm\\third_party\n",
            "      copying vllm\\third_party\\pynvml.py -> build\\lib\\vllm\\third_party\n",
            "      copying vllm\\third_party\\__init__.py -> build\\lib\\vllm\\third_party\n",
            "      creating build\\lib\\vllm\\tokenizers\n",
            "      copying vllm\\tokenizers\\detokenizer_utils.py -> build\\lib\\vllm\\tokenizers\n",
            "      copying vllm\\tokenizers\\hf.py -> build\\lib\\vllm\\tokenizers\n",
            "      copying vllm\\tokenizers\\mistral.py -> build\\lib\\vllm\\tokenizers\n",
            "      copying vllm\\tokenizers\\protocol.py -> build\\lib\\vllm\\tokenizers\n",
            "      copying vllm\\tokenizers\\registry.py -> build\\lib\\vllm\\tokenizers\n",
            "      copying vllm\\tokenizers\\__init__.py -> build\\lib\\vllm\\tokenizers\n",
            "      creating build\\lib\\vllm\\transformers_utils\n",
            "      copying vllm\\transformers_utils\\config.py -> build\\lib\\vllm\\transformers_utils\n",
            "      copying vllm\\transformers_utils\\config_parser_base.py -> build\\lib\\vllm\\transformers_utils\n",
            "      copying vllm\\transformers_utils\\dynamic_module.py -> build\\lib\\vllm\\transformers_utils\n",
            "      copying vllm\\transformers_utils\\gguf_utils.py -> build\\lib\\vllm\\transformers_utils\n",
            "      copying vllm\\transformers_utils\\processor.py -> build\\lib\\vllm\\transformers_utils\n",
            "      copying vllm\\transformers_utils\\repo_utils.py -> build\\lib\\vllm\\transformers_utils\n",
            "      copying vllm\\transformers_utils\\runai_utils.py -> build\\lib\\vllm\\transformers_utils\n",
            "      copying vllm\\transformers_utils\\s3_utils.py -> build\\lib\\vllm\\transformers_utils\n",
            "      copying vllm\\transformers_utils\\tokenizer.py -> build\\lib\\vllm\\transformers_utils\n",
            "      copying vllm\\transformers_utils\\tokenizer_base.py -> build\\lib\\vllm\\transformers_utils\n",
            "      copying vllm\\transformers_utils\\utils.py -> build\\lib\\vllm\\transformers_utils\n",
            "      copying vllm\\transformers_utils\\__init__.py -> build\\lib\\vllm\\transformers_utils\n",
            "      creating build\\lib\\vllm\\triton_utils\n",
            "      copying vllm\\triton_utils\\importing.py -> build\\lib\\vllm\\triton_utils\n",
            "      copying vllm\\triton_utils\\__init__.py -> build\\lib\\vllm\\triton_utils\n",
            "      creating build\\lib\\vllm\\usage\n",
            "      copying vllm\\usage\\usage_lib.py -> build\\lib\\vllm\\usage\n",
            "      copying vllm\\usage\\__init__.py -> build\\lib\\vllm\\usage\n",
            "      creating build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\argparse_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\async_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\cache.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\collection_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\counter.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\deep_gemm.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\flashinfer.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\func_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\gc_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\hashing.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\import_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\jsontree.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\math_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\mem_constants.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\mem_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\nccl.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\network_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\platform_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\profiling.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\registry.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\serial_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\system_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\tensor_schema.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\torch_utils.py -> build\\lib\\vllm\\utils\n",
            "      copying vllm\\utils\\__init__.py -> build\\lib\\vllm\\utils\n",
            "      creating build\\lib\\vllm\\v1\n",
            "      copying vllm\\v1\\cudagraph_dispatcher.py -> build\\lib\\vllm\\v1\n",
            "      copying vllm\\v1\\kv_cache_interface.py -> build\\lib\\vllm\\v1\n",
            "      copying vllm\\v1\\outputs.py -> build\\lib\\vllm\\v1\n",
            "      copying vllm\\v1\\request.py -> build\\lib\\vllm\\v1\n",
            "      copying vllm\\v1\\serial_utils.py -> build\\lib\\vllm\\v1\n",
            "      copying vllm\\v1\\utils.py -> build\\lib\\vllm\\v1\n",
            "      copying vllm\\v1\\__init__.py -> build\\lib\\vllm\\v1\n",
            "      creating build\\lib\\vllm\\attention\\backends\n",
            "      copying vllm\\attention\\backends\\abstract.py -> build\\lib\\vllm\\attention\\backends\n",
            "      copying vllm\\attention\\backends\\registry.py -> build\\lib\\vllm\\attention\\backends\n",
            "      copying vllm\\attention\\backends\\utils.py -> build\\lib\\vllm\\attention\\backends\n",
            "      copying vllm\\attention\\backends\\__init__.py -> build\\lib\\vllm\\attention\\backends\n",
            "      creating build\\lib\\vllm\\attention\\layers\n",
            "      copying vllm\\attention\\layers\\chunked_local_attention.py -> build\\lib\\vllm\\attention\\layers\n",
            "      copying vllm\\attention\\layers\\cross_attention.py -> build\\lib\\vllm\\attention\\layers\n",
            "      copying vllm\\attention\\layers\\encoder_only_attention.py -> build\\lib\\vllm\\attention\\layers\n",
            "      copying vllm\\attention\\layers\\__init__.py -> build\\lib\\vllm\\attention\\layers\n",
            "      creating build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\chunked_prefill_paged_decode.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\common.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\flashmla.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\merge_attn_states.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\paged_attn.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\pallas_kv_cache_update.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\prefix_prefill.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\rocm_aiter_mla_sparse.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\triton_decode_attention.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\triton_merge_attn_states.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\triton_reshape_and_cache_flash.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\triton_unified_attention.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\vit_attn_wrappers.py -> build\\lib\\vllm\\attention\\ops\n",
            "      copying vllm\\attention\\ops\\__init__.py -> build\\lib\\vllm\\attention\\ops\n",
            "      creating build\\lib\\vllm\\attention\\utils\n",
            "      copying vllm\\attention\\utils\\fa_utils.py -> build\\lib\\vllm\\attention\\utils\n",
            "      copying vllm\\attention\\utils\\kv_sharing_utils.py -> build\\lib\\vllm\\attention\\utils\n",
            "      copying vllm\\attention\\utils\\kv_transfer_utils.py -> build\\lib\\vllm\\attention\\utils\n",
            "      copying vllm\\attention\\utils\\__init__.py -> build\\lib\\vllm\\attention\\utils\n",
            "      creating build\\lib\\vllm\\benchmarks\\lib\n",
            "      copying vllm\\benchmarks\\lib\\endpoint_request_func.py -> build\\lib\\vllm\\benchmarks\\lib\n",
            "      copying vllm\\benchmarks\\lib\\ready_checker.py -> build\\lib\\vllm\\benchmarks\\lib\n",
            "      copying vllm\\benchmarks\\lib\\utils.py -> build\\lib\\vllm\\benchmarks\\lib\n",
            "      copying vllm\\benchmarks\\lib\\__init__.py -> build\\lib\\vllm\\benchmarks\\lib\n",
            "      creating build\\lib\\vllm\\benchmarks\\sweep\n",
            "      copying vllm\\benchmarks\\sweep\\cli.py -> build\\lib\\vllm\\benchmarks\\sweep\n",
            "      copying vllm\\benchmarks\\sweep\\param_sweep.py -> build\\lib\\vllm\\benchmarks\\sweep\n",
            "      copying vllm\\benchmarks\\sweep\\plot.py -> build\\lib\\vllm\\benchmarks\\sweep\n",
            "      copying vllm\\benchmarks\\sweep\\plot_pareto.py -> build\\lib\\vllm\\benchmarks\\sweep\n",
            "      copying vllm\\benchmarks\\sweep\\serve.py -> build\\lib\\vllm\\benchmarks\\sweep\n",
            "      copying vllm\\benchmarks\\sweep\\server.py -> build\\lib\\vllm\\benchmarks\\sweep\n",
            "      copying vllm\\benchmarks\\sweep\\serve_sla.py -> build\\lib\\vllm\\benchmarks\\sweep\n",
            "      copying vllm\\benchmarks\\sweep\\sla_sweep.py -> build\\lib\\vllm\\benchmarks\\sweep\n",
            "      copying vllm\\benchmarks\\sweep\\utils.py -> build\\lib\\vllm\\benchmarks\\sweep\n",
            "      copying vllm\\benchmarks\\sweep\\__init__.py -> build\\lib\\vllm\\benchmarks\\sweep\n",
            "      creating build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\all2all.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\all_reduce_utils.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\base_device_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\cpu_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\cuda_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\cuda_wrapper.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\custom_all_reduce.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\mnnvl_compat.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\pynccl.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\pynccl_allocator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\pynccl_wrapper.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\quick_all_reduce.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\ray_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\shm_broadcast.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\shm_object_storage.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\symm_mem.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\tpu_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\xpu_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      copying vllm\\distributed\\device_communicators\\__init__.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
            "      creating build\\lib\\vllm\\distributed\\ec_transfer\n",
            "      copying vllm\\distributed\\ec_transfer\\ec_transfer_state.py -> build\\lib\\vllm\\distributed\\ec_transfer\n",
            "      copying vllm\\distributed\\ec_transfer\\__init__.py -> build\\lib\\vllm\\distributed\\ec_transfer\n",
            "      creating build\\lib\\vllm\\distributed\\eplb\n",
            "      copying vllm\\distributed\\eplb\\async_worker.py -> build\\lib\\vllm\\distributed\\eplb\n",
            "      copying vllm\\distributed\\eplb\\eplb_state.py -> build\\lib\\vllm\\distributed\\eplb\n",
            "      copying vllm\\distributed\\eplb\\rebalance_algo.py -> build\\lib\\vllm\\distributed\\eplb\n",
            "      copying vllm\\distributed\\eplb\\rebalance_execute.py -> build\\lib\\vllm\\distributed\\eplb\n",
            "      copying vllm\\distributed\\eplb\\__init__.py -> build\\lib\\vllm\\distributed\\eplb\n",
            "      creating build\\lib\\vllm\\distributed\\kv_transfer\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_transfer_state.py -> build\\lib\\vllm\\distributed\\kv_transfer\n",
            "      copying vllm\\distributed\\kv_transfer\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\n",
            "      creating build\\lib\\vllm\\distributed\\ec_transfer\\ec_connector\n",
            "      copying vllm\\distributed\\ec_transfer\\ec_connector\\base.py -> build\\lib\\vllm\\distributed\\ec_transfer\\ec_connector\n",
            "      copying vllm\\distributed\\ec_transfer\\ec_connector\\factory.py -> build\\lib\\vllm\\distributed\\ec_transfer\\ec_connector\n",
            "      copying vllm\\distributed\\ec_transfer\\ec_connector\\shared_storage_connector.py -> build\\lib\\vllm\\distributed\\ec_transfer\\ec_connector\n",
            "      copying vllm\\distributed\\ec_transfer\\ec_connector\\__init__.py -> build\\lib\\vllm\\distributed\\ec_transfer\\ec_connector\n",
            "      creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\base.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\factory.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\utils.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
            "      creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\base.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\mooncake_store.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\simple_buffer.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
            "      creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_pipe\\base.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_pipe\\mooncake_pipe.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_pipe\\pynccl_pipe.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_pipe\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
            "      creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\base.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\decode_bench_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_mp_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\metrics.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\multi_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\nixl_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\offloading_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\shared_storage_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\\multi_process_adapter.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\\utils.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\\vllm_v1_adapter.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\n",
            "      creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\\p2p_nccl_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\\p2p_nccl_engine.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\\tensor_memory_pool.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\n",
            "      copying vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\n",
            "      creating build\\lib\\vllm\\entrypoints\\anthropic\n",
            "      copying vllm\\entrypoints\\anthropic\\protocol.py -> build\\lib\\vllm\\entrypoints\\anthropic\n",
            "      copying vllm\\entrypoints\\anthropic\\serving_messages.py -> build\\lib\\vllm\\entrypoints\\anthropic\n",
            "      copying vllm\\entrypoints\\anthropic\\__init__.py -> build\\lib\\vllm\\entrypoints\\anthropic\n",
            "      creating build\\lib\\vllm\\entrypoints\\cli\n",
            "      copying vllm\\entrypoints\\cli\\collect_env.py -> build\\lib\\vllm\\entrypoints\\cli\n",
            "      copying vllm\\entrypoints\\cli\\main.py -> build\\lib\\vllm\\entrypoints\\cli\n",
            "      copying vllm\\entrypoints\\cli\\openai.py -> build\\lib\\vllm\\entrypoints\\cli\n",
            "      copying vllm\\entrypoints\\cli\\run_batch.py -> build\\lib\\vllm\\entrypoints\\cli\n",
            "      copying vllm\\entrypoints\\cli\\serve.py -> build\\lib\\vllm\\entrypoints\\cli\n",
            "      copying vllm\\entrypoints\\cli\\types.py -> build\\lib\\vllm\\entrypoints\\cli\n",
            "      copying vllm\\entrypoints\\cli\\__init__.py -> build\\lib\\vllm\\entrypoints\\cli\n",
            "      creating build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\api_server.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\cli_args.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\orca_metrics.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\protocol.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\run_batch.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\serving_chat.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\serving_completion.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\serving_engine.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\serving_models.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\serving_responses.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\serving_tokenization.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\serving_tokens.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\serving_transcription.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\speech_to_text.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\utils.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      copying vllm\\entrypoints\\openai\\__init__.py -> build\\lib\\vllm\\entrypoints\\openai\n",
            "      creating build\\lib\\vllm\\entrypoints\\pooling\n",
            "      copying vllm\\entrypoints\\pooling\\__init__.py -> build\\lib\\vllm\\entrypoints\\pooling\n",
            "      creating build\\lib\\vllm\\entrypoints\\sagemaker\n",
            "      copying vllm\\entrypoints\\sagemaker\\routes.py -> build\\lib\\vllm\\entrypoints\\sagemaker\n",
            "      copying vllm\\entrypoints\\sagemaker\\__init__.py -> build\\lib\\vllm\\entrypoints\\sagemaker\n",
            "      creating build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying vllm\\entrypoints\\cli\\benchmark\\base.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying vllm\\entrypoints\\cli\\benchmark\\latency.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying vllm\\entrypoints\\cli\\benchmark\\main.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying vllm\\entrypoints\\cli\\benchmark\\serve.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying vllm\\entrypoints\\cli\\benchmark\\sweep.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying vllm\\entrypoints\\cli\\benchmark\\throughput.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying vllm\\entrypoints\\cli\\benchmark\\__init__.py -> build\\lib\\vllm\\entrypoints\\cli\\benchmark\n",
            "      creating build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\abstract_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\deepseekv31_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\deepseekv3_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\ernie45_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\glm4_moe_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\granite_20b_fc_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\granite_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\hermes_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\hunyuan_a13b_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\internlm2_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\jamba_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\kimi_k2_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\llama4_pythonic_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\llama_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\longcat_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\minimax_m2_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\minimax_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\mistral_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\olmo3_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\openai_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\phi4mini_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\pythonic_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\qwen3coder_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\qwen3xml_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\seed_oss_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\step3_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\utils.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\xlam_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying vllm\\entrypoints\\openai\\tool_parsers\\__init__.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      creating build\\lib\\vllm\\entrypoints\\pooling\\classify\n",
            "      copying vllm\\entrypoints\\pooling\\classify\\api_router.py -> build\\lib\\vllm\\entrypoints\\pooling\\classify\n",
            "      copying vllm\\entrypoints\\pooling\\classify\\protocol.py -> build\\lib\\vllm\\entrypoints\\pooling\\classify\n",
            "      copying vllm\\entrypoints\\pooling\\classify\\serving.py -> build\\lib\\vllm\\entrypoints\\pooling\\classify\n",
            "      copying vllm\\entrypoints\\pooling\\classify\\__init__.py -> build\\lib\\vllm\\entrypoints\\pooling\\classify\n",
            "      creating build\\lib\\vllm\\entrypoints\\pooling\\embed\n",
            "      copying vllm\\entrypoints\\pooling\\embed\\api_router.py -> build\\lib\\vllm\\entrypoints\\pooling\\embed\n",
            "      copying vllm\\entrypoints\\pooling\\embed\\protocol.py -> build\\lib\\vllm\\entrypoints\\pooling\\embed\n",
            "      copying vllm\\entrypoints\\pooling\\embed\\serving.py -> build\\lib\\vllm\\entrypoints\\pooling\\embed\n",
            "      copying vllm\\entrypoints\\pooling\\embed\\__init__.py -> build\\lib\\vllm\\entrypoints\\pooling\\embed\n",
            "      creating build\\lib\\vllm\\entrypoints\\pooling\\pooling\n",
            "      copying vllm\\entrypoints\\pooling\\pooling\\api_router.py -> build\\lib\\vllm\\entrypoints\\pooling\\pooling\n",
            "      copying vllm\\entrypoints\\pooling\\pooling\\protocol.py -> build\\lib\\vllm\\entrypoints\\pooling\\pooling\n",
            "      copying vllm\\entrypoints\\pooling\\pooling\\serving.py -> build\\lib\\vllm\\entrypoints\\pooling\\pooling\n",
            "      copying vllm\\entrypoints\\pooling\\pooling\\__init__.py -> build\\lib\\vllm\\entrypoints\\pooling\\pooling\n",
            "      creating build\\lib\\vllm\\entrypoints\\pooling\\score\n",
            "      copying vllm\\entrypoints\\pooling\\score\\api_router.py -> build\\lib\\vllm\\entrypoints\\pooling\\score\n",
            "      copying vllm\\entrypoints\\pooling\\score\\protocol.py -> build\\lib\\vllm\\entrypoints\\pooling\\score\n",
            "      copying vllm\\entrypoints\\pooling\\score\\serving.py -> build\\lib\\vllm\\entrypoints\\pooling\\score\n",
            "      copying vllm\\entrypoints\\pooling\\score\\__init__.py -> build\\lib\\vllm\\entrypoints\\pooling\\score\n",
            "      creating build\\lib\\vllm\\lora\\layers\n",
            "      copying vllm\\lora\\layers\\base.py -> build\\lib\\vllm\\lora\\layers\n",
            "      copying vllm\\lora\\layers\\base_linear.py -> build\\lib\\vllm\\lora\\layers\n",
            "      copying vllm\\lora\\layers\\column_parallel_linear.py -> build\\lib\\vllm\\lora\\layers\n",
            "      copying vllm\\lora\\layers\\fused_moe.py -> build\\lib\\vllm\\lora\\layers\n",
            "      copying vllm\\lora\\layers\\logits_processor.py -> build\\lib\\vllm\\lora\\layers\n",
            "      copying vllm\\lora\\layers\\replicated_linear.py -> build\\lib\\vllm\\lora\\layers\n",
            "      copying vllm\\lora\\layers\\row_parallel_linear.py -> build\\lib\\vllm\\lora\\layers\n",
            "      copying vllm\\lora\\layers\\utils.py -> build\\lib\\vllm\\lora\\layers\n",
            "      copying vllm\\lora\\layers\\vocal_parallel_embedding.py -> build\\lib\\vllm\\lora\\layers\n",
            "      copying vllm\\lora\\layers\\__init__.py -> build\\lib\\vllm\\lora\\layers\n",
            "      creating build\\lib\\vllm\\lora\\ops\n",
            "      copying vllm\\lora\\ops\\__init__.py -> build\\lib\\vllm\\lora\\ops\n",
            "      creating build\\lib\\vllm\\lora\\punica_wrapper\n",
            "      copying vllm\\lora\\punica_wrapper\\punica_base.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
            "      copying vllm\\lora\\punica_wrapper\\punica_cpu.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
            "      copying vllm\\lora\\punica_wrapper\\punica_gpu.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
            "      copying vllm\\lora\\punica_wrapper\\punica_selector.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
            "      copying vllm\\lora\\punica_wrapper\\punica_tpu.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
            "      copying vllm\\lora\\punica_wrapper\\punica_xpu.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
            "      copying vllm\\lora\\punica_wrapper\\utils.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
            "      copying vllm\\lora\\punica_wrapper\\__init__.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
            "      creating build\\lib\\vllm\\lora\\ops\\ipex_ops\n",
            "      copying vllm\\lora\\ops\\ipex_ops\\lora_ops.py -> build\\lib\\vllm\\lora\\ops\\ipex_ops\n",
            "      copying vllm\\lora\\ops\\ipex_ops\\__init__.py -> build\\lib\\vllm\\lora\\ops\\ipex_ops\n",
            "      creating build\\lib\\vllm\\lora\\ops\\torch_ops\n",
            "      copying vllm\\lora\\ops\\torch_ops\\lora_ops.py -> build\\lib\\vllm\\lora\\ops\\torch_ops\n",
            "      copying vllm\\lora\\ops\\torch_ops\\__init__.py -> build\\lib\\vllm\\lora\\ops\\torch_ops\n",
            "      creating build\\lib\\vllm\\lora\\ops\\triton_ops\n",
            "      copying vllm\\lora\\ops\\triton_ops\\fused_moe_lora_op.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
            "      copying vllm\\lora\\ops\\triton_ops\\kernel_utils.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
            "      copying vllm\\lora\\ops\\triton_ops\\lora_expand_op.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
            "      copying vllm\\lora\\ops\\triton_ops\\lora_kernel_metadata.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
            "      copying vllm\\lora\\ops\\triton_ops\\lora_shrink_op.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
            "      copying vllm\\lora\\ops\\triton_ops\\utils.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
            "      copying vllm\\lora\\ops\\triton_ops\\__init__.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
            "      creating build\\lib\\vllm\\lora\\ops\\xla_ops\n",
            "      copying vllm\\lora\\ops\\xla_ops\\lora_ops.py -> build\\lib\\vllm\\lora\\ops\\xla_ops\n",
            "      copying vllm\\lora\\ops\\xla_ops\\__init__.py -> build\\lib\\vllm\\lora\\ops\\xla_ops\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\activation.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\attention_layer_base.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\batch_invariant.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\conv.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\kda.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\layernorm.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\lightning_attn.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\linear.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\logits_processor.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\mla.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\pooler.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\resampler.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\utils.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\vocab_parallel_embedding.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      copying vllm\\model_executor\\layers\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\n",
            "      creating build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\adapters.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\afmoe.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\aimv2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\apertus.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\arcee.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\arctic.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\aria.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\aya_vision.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\baichuan.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\bailing_moe.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\bamba.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\bee.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\bert.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\bert_with_rope.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\blip.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\blip2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\bloom.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\chameleon.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\chatglm.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\clip.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\cohere2_vision.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\commandr.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\config.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\dbrx.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\deepencoder.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\deepseek_eagle.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\deepseek_mtp.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\deepseek_ocr.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\deepseek_v2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\deepseek_vl2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\dots1.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\dots_ocr.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\ernie45.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\ernie45_moe.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\ernie45_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\ernie45_vl_moe.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\ernie_mtp.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\exaone.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\exaone4.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\fairseq2_llama.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\falcon.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\falcon_h1.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\flex_olmo.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\fuyu.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\gemma.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\gemma2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\gemma3.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\gemma3n.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\gemma3n_mm.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\gemma3_mm.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\glm.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\glm4.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\glm4v.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\glm4_1v.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\glm4_moe.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\glm4_moe_mtp.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\gpt2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\gpt_bigcode.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\gpt_j.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\gpt_neox.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\gpt_oss.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\granite.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\granitemoe.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\granitemoehybrid.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\granitemoeshared.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\granite_speech.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\gritlm.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\grok1.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\h2ovl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\hunyuan_v1.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\hunyuan_vision.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\hyperclovax_vision.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\idefics2_vision_model.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\idefics3.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\interfaces.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\interfaces_base.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\internlm2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\internlm2_ve.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\interns1.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\interns1_vit.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\internvl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\intern_vit.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\jais.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\jamba.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\jina_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\keye.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\keye_vl1_5.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\kimi_linear.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\kimi_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\lfm2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\lfm2_moe.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\lightonocr.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\llama.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\llama4.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\llama4_eagle.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\llama_eagle.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\llama_eagle3.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\llava.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\llava_next.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\llava_next_video.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\llava_onevision.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\longcat_flash.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\longcat_flash_mtp.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\mamba.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\mamba2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\medusa.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\midashenglm.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\mimo.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\mimo_mtp.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\minicpm.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\minicpm3.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\minicpmo.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\minicpmv.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\minicpm_eagle.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\minimax_m2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\minimax_text_01.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\minimax_vl_01.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\mistral3.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\mistral_large_3.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\mistral_large_3_eagle.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\mixtral.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\mllama4.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\mlp_speculator.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\modernbert.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\module_mapping.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\molmo.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\moonvit.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\mpt.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\nano_nemotron_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\nemotron.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\nemotron_h.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\nemotron_nas.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\nemotron_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\nvlm_d.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\olmo.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\olmo2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\olmoe.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\opencua.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\openpangu.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\openpangu_mtp.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\opt.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\orion.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\ouro.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\ovis.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\ovis2_5.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\paddleocr_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\paligemma.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\persimmon.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\phi.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\phi3.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\phi3v.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\phi4mm.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\phi4mm_audio.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\phi4mm_utils.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\phi4_multimodal.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\phimoe.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\pixtral.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\plamo2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\plamo3.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen2_5_omni_thinker.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen2_5_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen2_audio.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen2_moe.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen2_rm.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen2_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen3.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen3_moe.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen3_next.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen3_next_mtp.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen3_omni_moe_thinker.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen3_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen3_vl_moe.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\qwen_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\radio.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\registry.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\roberta.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\rvl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\seed_oss.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\siglip.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\siglip2navit.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\skyworkr1v.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\smolvlm.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\solar.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\stablelm.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\starcoder2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\step3_text.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\step3_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\swin.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\tarsier.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\telechat2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\teleflm.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\terratorch.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\ultravox.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\utils.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\vision.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\voxtral.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\whisper.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\zamba2.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      copying vllm\\model_executor\\models\\__init__.py -> build\\lib\\vllm\\model_executor\\models\n",
            "      creating build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\base_loader.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\bitsandbytes_loader.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\default_loader.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\dummy_loader.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\gguf_loader.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\online_quantization.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\runai_streamer_loader.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\sharded_state_loader.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\tensorizer.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\tensorizer_loader.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\tpu.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\utils.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\weight_utils.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      copying vllm\\model_executor\\model_loader\\__init__.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
            "      creating build\\lib\\vllm\\model_executor\\warmup\n",
            "      copying vllm\\model_executor\\warmup\\deep_gemm_warmup.py -> build\\lib\\vllm\\model_executor\\warmup\n",
            "      copying vllm\\model_executor\\warmup\\kernel_warmup.py -> build\\lib\\vllm\\model_executor\\warmup\n",
            "      copying vllm\\model_executor\\warmup\\__init__.py -> build\\lib\\vllm\\model_executor\\warmup\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\fla\n",
            "      copying vllm\\model_executor\\layers\\fla\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\fla\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\all2all_utils.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\batched_deep_gemm_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\batched_triton_or_deep_gemm_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\config.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\cpu_fused_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\cutlass_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\deepep_ht_prepare_finalize.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\deepep_ll_prepare_finalize.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\deep_gemm_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\deep_gemm_utils.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\flashinfer_cutedsl_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\flashinfer_cutlass_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\flashinfer_cutlass_prepare_finalize.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\flashinfer_trtllm_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\fused_batched_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\fused_marlin_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\fused_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\fused_moe_method_base.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\fused_moe_modular_method.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\gpt_oss_triton_kernels_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\layer.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\modular_kernel.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\moe_align_block_size.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\moe_pallas.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\moe_permute_unpermute.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\moe_torch_iterative.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\pplx_prepare_finalize.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\prepare_finalize.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\rocm_aiter_fused_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\routing_simulator.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\shared_fused_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\topk_weight_and_reduce.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\triton_deep_gemm_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\trtllm_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\unquantized_fused_moe_method.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\utils.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\mamba\n",
            "      copying vllm\\model_executor\\layers\\mamba\\abstract.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
            "      copying vllm\\model_executor\\layers\\mamba\\linear_attn.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
            "      copying vllm\\model_executor\\layers\\mamba\\mamba_mixer.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
            "      copying vllm\\model_executor\\layers\\mamba\\mamba_mixer2.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
            "      copying vllm\\model_executor\\layers\\mamba\\mamba_utils.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
            "      copying vllm\\model_executor\\layers\\mamba\\short_conv.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
            "      copying vllm\\model_executor\\layers\\mamba\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\auto_round.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\awq.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\awq_marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\awq_triton.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\base_config.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\bitblas.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\bitsandbytes.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\cpu_wna16.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\deepspeedfp.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\experts_int8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\fbgemm_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\fp_quant.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\gguf.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\gptq.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\gptq_bitblas.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\gptq_marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\gptq_marlin_24.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\hqq_marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\inc.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\input_quant_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\ipex_quant.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kv_cache.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\modelopt.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\moe_wna16.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\mxfp4.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\petit.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\ptpc_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\qutlass_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\rtn.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\schema.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\torchao.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\tpu_int8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      copying vllm\\model_executor\\layers\\quantization\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\base.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\common.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\deepseek_scaling_rope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\dual_chunk_rope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\dynamic_ntk_alpha_rope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\dynamic_ntk_scaling_rope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\ernie45_vl_rope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\linear_scaling_rope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\llama3_rope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\llama4_vision_rope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\mrope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\ntk_scaling_rope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\phi3_long_rope_scaled_rope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\xdrope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\yarn_scaling_rope.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      copying vllm\\model_executor\\layers\\rotary_embedding\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\rotary_embedding\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\chunk.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\chunk_delta_h.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\chunk_o.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\chunk_scaled_dot_kkt.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\cumsum.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\fused_recurrent.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\index.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\kda.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\l2norm.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\layernorm_guard.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\op.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\solve_tril.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\utils.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\wy_fast.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying vllm\\model_executor\\layers\\fla\\ops\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying vllm\\model_executor\\layers\\mamba\\ops\\causal_conv1d.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying vllm\\model_executor\\layers\\mamba\\ops\\layernorm_gated.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying vllm\\model_executor\\layers\\mamba\\ops\\mamba_ssm.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_bmm.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_chunk_scan.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_chunk_state.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_combined.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_state_passing.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying vllm\\model_executor\\layers\\mamba\\ops\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\compressed_tensors.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\compressed_tensors_moe.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\triton_scaled_mm.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
            "      copying vllm\\model_executor\\layers\\quantization\\quark\\quark.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
            "      copying vllm\\model_executor\\layers\\quantization\\quark\\quark_moe.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
            "      copying vllm\\model_executor\\layers\\quantization\\quark\\utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
            "      copying vllm\\model_executor\\layers\\quantization\\quark\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\allspark_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\bitblas_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\flashinfer_fp4_moe.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\flashinfer_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\fp8_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\gptq_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\int8_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\layer_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\machete_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils_fp4.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils_test.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils_test_24.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\mxfp4_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\mxfp6_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\mxfp8_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\nvfp4_emulation_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\nvfp4_moe_support.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\ocp_mx_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\petit_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\quant_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\w8a8_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_24.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_scheme.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a16_24.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a16_nvfp4.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a4_nvfp4.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a8_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a8_int.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a16_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a8_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a8_int8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_wNa16.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\linear.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\module.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\schemes\\linear_qutlass_nvfp4.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\schemes\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\schemes\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\allspark.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\bitblas.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\conch.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\cutlass.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\dynamic_4bit.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\exllama.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\machete.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\MPLinearKernel.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\aiter.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\cpu.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\cutlass.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\ScaledMMLinearKernel.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\triton.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\xla.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_ocp_mx.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_scheme.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_w8a8_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_w8a8_int8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
            "      copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
            "      creating build\\lib\\vllm\\model_executor\\models\\transformers\n",
            "      copying vllm\\model_executor\\models\\transformers\\base.py -> build\\lib\\vllm\\model_executor\\models\\transformers\n",
            "      copying vllm\\model_executor\\models\\transformers\\causal.py -> build\\lib\\vllm\\model_executor\\models\\transformers\n",
            "      copying vllm\\model_executor\\models\\transformers\\legacy.py -> build\\lib\\vllm\\model_executor\\models\\transformers\n",
            "      copying vllm\\model_executor\\models\\transformers\\moe.py -> build\\lib\\vllm\\model_executor\\models\\transformers\n",
            "      copying vllm\\model_executor\\models\\transformers\\multimodal.py -> build\\lib\\vllm\\model_executor\\models\\transformers\n",
            "      copying vllm\\model_executor\\models\\transformers\\pooling.py -> build\\lib\\vllm\\model_executor\\models\\transformers\n",
            "      copying vllm\\model_executor\\models\\transformers\\utils.py -> build\\lib\\vllm\\model_executor\\models\\transformers\n",
            "      copying vllm\\model_executor\\models\\transformers\\__init__.py -> build\\lib\\vllm\\model_executor\\models\\transformers\n",
            "      creating build\\lib\\vllm\\plugins\\io_processors\n",
            "      copying vllm\\plugins\\io_processors\\interface.py -> build\\lib\\vllm\\plugins\\io_processors\n",
            "      copying vllm\\plugins\\io_processors\\__init__.py -> build\\lib\\vllm\\plugins\\io_processors\n",
            "      creating build\\lib\\vllm\\plugins\\lora_resolvers\n",
            "      copying vllm\\plugins\\lora_resolvers\\filesystem_resolver.py -> build\\lib\\vllm\\plugins\\lora_resolvers\n",
            "      copying vllm\\plugins\\lora_resolvers\\__init__.py -> build\\lib\\vllm\\plugins\\lora_resolvers\n",
            "      creating build\\lib\\vllm\\transformers_utils\\chat_templates\n",
            "      copying vllm\\transformers_utils\\chat_templates\\registry.py -> build\\lib\\vllm\\transformers_utils\\chat_templates\n",
            "      copying vllm\\transformers_utils\\chat_templates\\__init__.py -> build\\lib\\vllm\\transformers_utils\\chat_templates\n",
            "      creating build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\afmoe.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\arctic.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\chatglm.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\deepseek_vl2.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\dotsocr.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\eagle.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\falcon.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\flex_olmo.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\hunyuan_vl.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\jais.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\kimi_linear.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\kimi_vl.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\lfm2_moe.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\medusa.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\midashenglm.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\mistral.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\mlp_speculator.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\moonvit.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\nemotron.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\nemotron_h.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\olmo3.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\ovis.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\qwen3_next.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\radio.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\step3_vl.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\ultravox.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      copying vllm\\transformers_utils\\configs\\__init__.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
            "      creating build\\lib\\vllm\\transformers_utils\\processors\n",
            "      copying vllm\\transformers_utils\\processors\\deepseek_ocr.py -> build\\lib\\vllm\\transformers_utils\\processors\n",
            "      copying vllm\\transformers_utils\\processors\\deepseek_vl2.py -> build\\lib\\vllm\\transformers_utils\\processors\n",
            "      copying vllm\\transformers_utils\\processors\\hunyuan_vl.py -> build\\lib\\vllm\\transformers_utils\\processors\n",
            "      copying vllm\\transformers_utils\\processors\\hunyuan_vl_image.py -> build\\lib\\vllm\\transformers_utils\\processors\n",
            "      copying vllm\\transformers_utils\\processors\\ovis.py -> build\\lib\\vllm\\transformers_utils\\processors\n",
            "      copying vllm\\transformers_utils\\processors\\ovis2_5.py -> build\\lib\\vllm\\transformers_utils\\processors\n",
            "      copying vllm\\transformers_utils\\processors\\__init__.py -> build\\lib\\vllm\\transformers_utils\\processors\n",
            "      creating build\\lib\\vllm\\transformers_utils\\configs\\speculators\n",
            "      copying vllm\\transformers_utils\\configs\\speculators\\algos.py -> build\\lib\\vllm\\transformers_utils\\configs\\speculators\n",
            "      copying vllm\\transformers_utils\\configs\\speculators\\base.py -> build\\lib\\vllm\\transformers_utils\\configs\\speculators\n",
            "      copying vllm\\transformers_utils\\configs\\speculators\\__init__.py -> build\\lib\\vllm\\transformers_utils\\configs\\speculators\n",
            "      creating build\\lib\\vllm\\v1\\attention\n",
            "      copying vllm\\v1\\attention\\__init__.py -> build\\lib\\vllm\\v1\\attention\n",
            "      creating build\\lib\\vllm\\v1\\core\n",
            "      copying vllm\\v1\\core\\block_pool.py -> build\\lib\\vllm\\v1\\core\n",
            "      copying vllm\\v1\\core\\encoder_cache_manager.py -> build\\lib\\vllm\\v1\\core\n",
            "      copying vllm\\v1\\core\\kv_cache_coordinator.py -> build\\lib\\vllm\\v1\\core\n",
            "      copying vllm\\v1\\core\\kv_cache_manager.py -> build\\lib\\vllm\\v1\\core\n",
            "      copying vllm\\v1\\core\\kv_cache_metrics.py -> build\\lib\\vllm\\v1\\core\n",
            "      copying vllm\\v1\\core\\kv_cache_utils.py -> build\\lib\\vllm\\v1\\core\n",
            "      copying vllm\\v1\\core\\single_type_kv_cache_manager.py -> build\\lib\\vllm\\v1\\core\n",
            "      copying vllm\\v1\\core\\__init__.py -> build\\lib\\vllm\\v1\\core\n",
            "      creating build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\async_llm.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\coordinator.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\core.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\core_client.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\detokenizer.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\exceptions.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\input_processor.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\llm_engine.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\logprobs.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\output_processor.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\parallel_sampling.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\processor.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\utils.py -> build\\lib\\vllm\\v1\\engine\n",
            "      copying vllm\\v1\\engine\\__init__.py -> build\\lib\\vllm\\v1\\engine\n",
            "      creating build\\lib\\vllm\\v1\\executor\n",
            "      copying vllm\\v1\\executor\\abstract.py -> build\\lib\\vllm\\v1\\executor\n",
            "      copying vllm\\v1\\executor\\multiproc_executor.py -> build\\lib\\vllm\\v1\\executor\n",
            "      copying vllm\\v1\\executor\\ray_distributed_executor.py -> build\\lib\\vllm\\v1\\executor\n",
            "      copying vllm\\v1\\executor\\ray_executor.py -> build\\lib\\vllm\\v1\\executor\n",
            "      copying vllm\\v1\\executor\\ray_utils.py -> build\\lib\\vllm\\v1\\executor\n",
            "      copying vllm\\v1\\executor\\uniproc_executor.py -> build\\lib\\vllm\\v1\\executor\n",
            "      copying vllm\\v1\\executor\\__init__.py -> build\\lib\\vllm\\v1\\executor\n",
            "      creating build\\lib\\vllm\\v1\\kv_offload\n",
            "      copying vllm\\v1\\kv_offload\\abstract.py -> build\\lib\\vllm\\v1\\kv_offload\n",
            "      copying vllm\\v1\\kv_offload\\arc_manager.py -> build\\lib\\vllm\\v1\\kv_offload\n",
            "      copying vllm\\v1\\kv_offload\\backend.py -> build\\lib\\vllm\\v1\\kv_offload\n",
            "      copying vllm\\v1\\kv_offload\\cpu.py -> build\\lib\\vllm\\v1\\kv_offload\n",
            "      copying vllm\\v1\\kv_offload\\factory.py -> build\\lib\\vllm\\v1\\kv_offload\n",
            "      copying vllm\\v1\\kv_offload\\lru_manager.py -> build\\lib\\vllm\\v1\\kv_offload\n",
            "      copying vllm\\v1\\kv_offload\\mediums.py -> build\\lib\\vllm\\v1\\kv_offload\n",
            "      copying vllm\\v1\\kv_offload\\spec.py -> build\\lib\\vllm\\v1\\kv_offload\n",
            "      copying vllm\\v1\\kv_offload\\__init__.py -> build\\lib\\vllm\\v1\\kv_offload\n",
            "      creating build\\lib\\vllm\\v1\\metrics\n",
            "      copying vllm\\v1\\metrics\\loggers.py -> build\\lib\\vllm\\v1\\metrics\n",
            "      copying vllm\\v1\\metrics\\prometheus.py -> build\\lib\\vllm\\v1\\metrics\n",
            "      copying vllm\\v1\\metrics\\ray_wrappers.py -> build\\lib\\vllm\\v1\\metrics\n",
            "      copying vllm\\v1\\metrics\\reader.py -> build\\lib\\vllm\\v1\\metrics\n",
            "      copying vllm\\v1\\metrics\\stats.py -> build\\lib\\vllm\\v1\\metrics\n",
            "      copying vllm\\v1\\metrics\\__init__.py -> build\\lib\\vllm\\v1\\metrics\n",
            "      creating build\\lib\\vllm\\v1\\pool\n",
            "      copying vllm\\v1\\pool\\metadata.py -> build\\lib\\vllm\\v1\\pool\n",
            "      copying vllm\\v1\\pool\\__init__.py -> build\\lib\\vllm\\v1\\pool\n",
            "      creating build\\lib\\vllm\\v1\\sample\n",
            "      copying vllm\\v1\\sample\\metadata.py -> build\\lib\\vllm\\v1\\sample\n",
            "      copying vllm\\v1\\sample\\rejection_sampler.py -> build\\lib\\vllm\\v1\\sample\n",
            "      copying vllm\\v1\\sample\\sampler.py -> build\\lib\\vllm\\v1\\sample\n",
            "      copying vllm\\v1\\sample\\__init__.py -> build\\lib\\vllm\\v1\\sample\n",
            "      creating build\\lib\\vllm\\v1\\spec_decode\n",
            "      copying vllm\\v1\\spec_decode\\eagle.py -> build\\lib\\vllm\\v1\\spec_decode\n",
            "      copying vllm\\v1\\spec_decode\\medusa.py -> build\\lib\\vllm\\v1\\spec_decode\n",
            "      copying vllm\\v1\\spec_decode\\metadata.py -> build\\lib\\vllm\\v1\\spec_decode\n",
            "      copying vllm\\v1\\spec_decode\\metrics.py -> build\\lib\\vllm\\v1\\spec_decode\n",
            "      copying vllm\\v1\\spec_decode\\ngram_proposer.py -> build\\lib\\vllm\\v1\\spec_decode\n",
            "      copying vllm\\v1\\spec_decode\\suffix_decoding.py -> build\\lib\\vllm\\v1\\spec_decode\n",
            "      copying vllm\\v1\\spec_decode\\utils.py -> build\\lib\\vllm\\v1\\spec_decode\n",
            "      copying vllm\\v1\\spec_decode\\__init__.py -> build\\lib\\vllm\\v1\\spec_decode\n",
            "      creating build\\lib\\vllm\\v1\\structured_output\n",
            "      copying vllm\\v1\\structured_output\\backend_guidance.py -> build\\lib\\vllm\\v1\\structured_output\n",
            "      copying vllm\\v1\\structured_output\\backend_lm_format_enforcer.py -> build\\lib\\vllm\\v1\\structured_output\n",
            "      copying vllm\\v1\\structured_output\\backend_outlines.py -> build\\lib\\vllm\\v1\\structured_output\n",
            "      copying vllm\\v1\\structured_output\\backend_types.py -> build\\lib\\vllm\\v1\\structured_output\n",
            "      copying vllm\\v1\\structured_output\\backend_xgrammar.py -> build\\lib\\vllm\\v1\\structured_output\n",
            "      copying vllm\\v1\\structured_output\\request.py -> build\\lib\\vllm\\v1\\structured_output\n",
            "      copying vllm\\v1\\structured_output\\utils.py -> build\\lib\\vllm\\v1\\structured_output\n",
            "      copying vllm\\v1\\structured_output\\__init__.py -> build\\lib\\vllm\\v1\\structured_output\n",
            "      creating build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\block_table.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\cpu_model_runner.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\cpu_worker.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\dp_utils.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\ec_connector_model_runner_mixin.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\gpu_input_batch.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\gpu_model_runner.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\gpu_ubatch_wrapper.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\gpu_worker.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\kv_connector_model_runner_mixin.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\lora_model_runner_mixin.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\tpu_input_batch.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\tpu_model_runner.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\tpu_worker.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\ubatching.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\ubatch_utils.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\utils.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\worker_base.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\xpu_model_runner.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\xpu_worker.py -> build\\lib\\vllm\\v1\\worker\n",
            "      copying vllm\\v1\\worker\\__init__.py -> build\\lib\\vllm\\v1\\worker\n",
            "      creating build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\cpu_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\flashinfer.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\flash_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\flex_attention.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\gdn_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\linear_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\mamba1_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\mamba2_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\mamba_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\pallas.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\rocm_aiter_fa.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\rocm_aiter_unified_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\rocm_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\short_conv_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\tree_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\triton_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\utils.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      copying vllm\\v1\\attention\\backends\\__init__.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
            "      creating build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      copying vllm\\v1\\attention\\backends\\mla\\aiter_triton_mla.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      copying vllm\\v1\\attention\\backends\\mla\\common.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      copying vllm\\v1\\attention\\backends\\mla\\cutlass_mla.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      copying vllm\\v1\\attention\\backends\\mla\\flashattn_mla.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      copying vllm\\v1\\attention\\backends\\mla\\flashinfer_mla.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      copying vllm\\v1\\attention\\backends\\mla\\flashmla.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      copying vllm\\v1\\attention\\backends\\mla\\flashmla_sparse.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      copying vllm\\v1\\attention\\backends\\mla\\indexer.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      copying vllm\\v1\\attention\\backends\\mla\\rocm_aiter_mla.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      copying vllm\\v1\\attention\\backends\\mla\\rocm_aiter_mla_sparse.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      copying vllm\\v1\\attention\\backends\\mla\\triton_mla.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      copying vllm\\v1\\attention\\backends\\mla\\__init__.py -> build\\lib\\vllm\\v1\\attention\\backends\\mla\n",
            "      creating build\\lib\\vllm\\v1\\core\\sched\n",
            "      copying vllm\\v1\\core\\sched\\async_scheduler.py -> build\\lib\\vllm\\v1\\core\\sched\n",
            "      copying vllm\\v1\\core\\sched\\interface.py -> build\\lib\\vllm\\v1\\core\\sched\n",
            "      copying vllm\\v1\\core\\sched\\output.py -> build\\lib\\vllm\\v1\\core\\sched\n",
            "      copying vllm\\v1\\core\\sched\\request_queue.py -> build\\lib\\vllm\\v1\\core\\sched\n",
            "      copying vllm\\v1\\core\\sched\\scheduler.py -> build\\lib\\vllm\\v1\\core\\sched\n",
            "      copying vllm\\v1\\core\\sched\\utils.py -> build\\lib\\vllm\\v1\\core\\sched\n",
            "      copying vllm\\v1\\core\\sched\\__init__.py -> build\\lib\\vllm\\v1\\core\\sched\n",
            "      creating build\\lib\\vllm\\v1\\kv_offload\\backends\n",
            "      copying vllm\\v1\\kv_offload\\backends\\cpu.py -> build\\lib\\vllm\\v1\\kv_offload\\backends\n",
            "      copying vllm\\v1\\kv_offload\\backends\\__init__.py -> build\\lib\\vllm\\v1\\kv_offload\\backends\n",
            "      creating build\\lib\\vllm\\v1\\kv_offload\\worker\n",
            "      copying vllm\\v1\\kv_offload\\worker\\cpu_gpu.py -> build\\lib\\vllm\\v1\\kv_offload\\worker\n",
            "      copying vllm\\v1\\kv_offload\\worker\\worker.py -> build\\lib\\vllm\\v1\\kv_offload\\worker\n",
            "      copying vllm\\v1\\kv_offload\\worker\\__init__.py -> build\\lib\\vllm\\v1\\kv_offload\\worker\n",
            "      creating build\\lib\\vllm\\v1\\sample\\logits_processor\n",
            "      copying vllm\\v1\\sample\\logits_processor\\builtin.py -> build\\lib\\vllm\\v1\\sample\\logits_processor\n",
            "      copying vllm\\v1\\sample\\logits_processor\\interface.py -> build\\lib\\vllm\\v1\\sample\\logits_processor\n",
            "      copying vllm\\v1\\sample\\logits_processor\\state.py -> build\\lib\\vllm\\v1\\sample\\logits_processor\n",
            "      copying vllm\\v1\\sample\\logits_processor\\__init__.py -> build\\lib\\vllm\\v1\\sample\\logits_processor\n",
            "      creating build\\lib\\vllm\\v1\\sample\\ops\n",
            "      copying vllm\\v1\\sample\\ops\\bad_words.py -> build\\lib\\vllm\\v1\\sample\\ops\n",
            "      copying vllm\\v1\\sample\\ops\\logprobs.py -> build\\lib\\vllm\\v1\\sample\\ops\n",
            "      copying vllm\\v1\\sample\\ops\\penalties.py -> build\\lib\\vllm\\v1\\sample\\ops\n",
            "      copying vllm\\v1\\sample\\ops\\topk_topp_sampler.py -> build\\lib\\vllm\\v1\\sample\\ops\n",
            "      copying vllm\\v1\\sample\\ops\\__init__.py -> build\\lib\\vllm\\v1\\sample\\ops\n",
            "      creating build\\lib\\vllm\\v1\\sample\\tpu\n",
            "      copying vllm\\v1\\sample\\tpu\\metadata.py -> build\\lib\\vllm\\v1\\sample\\tpu\n",
            "      copying vllm\\v1\\sample\\tpu\\sampler.py -> build\\lib\\vllm\\v1\\sample\\tpu\n",
            "      copying vllm\\v1\\sample\\tpu\\__init__.py -> build\\lib\\vllm\\v1\\sample\\tpu\n",
            "      creating build\\lib\\vllm\\v1\\worker\\gpu\n",
            "      copying vllm\\v1\\worker\\gpu\\async_utils.py -> build\\lib\\vllm\\v1\\worker\\gpu\n",
            "      copying vllm\\v1\\worker\\gpu\\attn_utils.py -> build\\lib\\vllm\\v1\\worker\\gpu\n",
            "      copying vllm\\v1\\worker\\gpu\\block_table.py -> build\\lib\\vllm\\v1\\worker\\gpu\n",
            "      copying vllm\\v1\\worker\\gpu\\cudagraph_utils.py -> build\\lib\\vllm\\v1\\worker\\gpu\n",
            "      copying vllm\\v1\\worker\\gpu\\dp_utils.py -> build\\lib\\vllm\\v1\\worker\\gpu\n",
            "      copying vllm\\v1\\worker\\gpu\\input_batch.py -> build\\lib\\vllm\\v1\\worker\\gpu\n",
            "      copying vllm\\v1\\worker\\gpu\\model_runner.py -> build\\lib\\vllm\\v1\\worker\\gpu\n",
            "      copying vllm\\v1\\worker\\gpu\\states.py -> build\\lib\\vllm\\v1\\worker\\gpu\n",
            "      copying vllm\\v1\\worker\\gpu\\structured_outputs.py -> build\\lib\\vllm\\v1\\worker\\gpu\n",
            "      copying vllm\\v1\\worker\\gpu\\__init__.py -> build\\lib\\vllm\\v1\\worker\\gpu\n",
            "      creating build\\lib\\vllm\\v1\\worker\\gpu\\sample\n",
            "      copying vllm\\v1\\worker\\gpu\\sample\\gumbel.py -> build\\lib\\vllm\\v1\\worker\\gpu\\sample\n",
            "      copying vllm\\v1\\worker\\gpu\\sample\\logprob.py -> build\\lib\\vllm\\v1\\worker\\gpu\\sample\n",
            "      copying vllm\\v1\\worker\\gpu\\sample\\metadata.py -> build\\lib\\vllm\\v1\\worker\\gpu\\sample\n",
            "      copying vllm\\v1\\worker\\gpu\\sample\\penalties.py -> build\\lib\\vllm\\v1\\worker\\gpu\\sample\n",
            "      copying vllm\\v1\\worker\\gpu\\sample\\sampler.py -> build\\lib\\vllm\\v1\\worker\\gpu\\sample\n",
            "      copying vllm\\v1\\worker\\gpu\\sample\\__init__.py -> build\\lib\\vllm\\v1\\worker\\gpu\\sample\n",
            "      creating build\\lib\\vllm\\v1\\worker\\gpu\\spec_decode\n",
            "      copying vllm\\v1\\worker\\gpu\\spec_decode\\eagle.py -> build\\lib\\vllm\\v1\\worker\\gpu\\spec_decode\n",
            "      copying vllm\\v1\\worker\\gpu\\spec_decode\\eagle_cudagraph.py -> build\\lib\\vllm\\v1\\worker\\gpu\\spec_decode\n",
            "      copying vllm\\v1\\worker\\gpu\\spec_decode\\rejection_sample.py -> build\\lib\\vllm\\v1\\worker\\gpu\\spec_decode\n",
            "      copying vllm\\v1\\worker\\gpu\\spec_decode\\__init__.py -> build\\lib\\vllm\\v1\\worker\\gpu\\spec_decode\n",
            "      running egg_info\n",
            "      writing vllm.egg-info\\PKG-INFO\n",
            "      writing dependency_links to vllm.egg-info\\dependency_links.txt\n",
            "      writing entry points to vllm.egg-info\\entry_points.txt\n",
            "      writing requirements to vllm.egg-info\\requires.txt\n",
            "      writing top-level names to vllm.egg-info\\top_level.txt\n",
            "      listing git files failed - pretending there aren't any\n",
            "      reading manifest file 'vllm.egg-info\\SOURCES.txt'\n",
            "      reading manifest template 'MANIFEST.in'\n",
            "      adding license file 'LICENSE'\n",
            "      writing manifest file 'vllm.egg-info\\SOURCES.txt'\n",
            "      copying vllm\\py.typed -> build\\lib\\vllm\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H200,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=NVIDIA_H100,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1856,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1856,device_name=NVIDIA_L40S.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H20-3e.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H20.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=352,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H20-3e.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H20.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=512,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=704,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=704,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=AMD_Instinct_MI308X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H20.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=bf16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=928,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=928,device_name=NVIDIA_L40S.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=96,device_name=NVIDIA_H20.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=NVIDIA_B200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=NVIDIA_H100.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2048,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_H200,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=192,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=192,device_name=AMD_Instinct_MI350_OAM,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=192,device_name=NVIDIA_H20-3e.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=320,device_name=NVIDIA_H20-3e.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=384,device_name=AMD_Instinct_MI350_OAM,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=384,device_name=AMD_Instinct_MI355_OAM,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=640,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=640,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=640,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=20,N=1536,device_name=NVIDIA_RTX_PRO_6000_Blackwell_Server_Edition,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=20,N=2560,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=20,N=2560,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=20,N=2560,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=32,N=1408,device_name=NVIDIA_B200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=32,N=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=32,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=384,N=128,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=384,N=128,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=384,N=128,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=384,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=384,N=256,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=40,N=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=40,N=2560,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=40,N=2560,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=40,N=2560,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=128,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=128,device_name=NVIDIA_B200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=128,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=128,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=128,device_name=NVIDIA_H20-3e.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=128,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=256,device_name=NVIDIA_B200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=256,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=256,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=256,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=256,device_name=NVIDIA_H20-3e.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=256,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=512,device_name=NVIDIA_B200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=512,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=512,device_name=NVIDIA_H20-3e.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=512,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=64,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=64,device_name=NVIDIA_B200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=64,device_name=NVIDIA_H20-3e.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=64,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=62,N=128,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=62,N=256,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=62,N=512,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1408,device_name=NVIDIA_B200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=2560,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=3072,device_name=NVIDIA_H20.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=320,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=384,device_name=NVIDIA_H20.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=768,device_name=NVIDIA_H100_PCIe,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=768,device_name=NVIDIA_H20.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=896,device_name=NVIDIA_H20.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=bf16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=72,N=192,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=72,N=384,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=72,N=768,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_L40S.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H200.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      creating build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=10240,K=5120,device_name=NVIDIA_L40S,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=12288,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=12288,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2112,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2112,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=5120,K=25600,device_name=NVIDIA_L40S,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=5120,K=8192,device_name=NVIDIA_L40S,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=51200,K=5120,device_name=NVIDIA_L40S,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      creating build\\lib\\vllm\\vllm_flash_attn\n",
            "      copying vllm\\vllm_flash_attn\\.gitkeep -> build\\lib\\vllm\\vllm_flash_attn\n",
            "      copying vllm\\distributed\\kv_transfer\\README.md -> build\\lib\\vllm\\distributed\\kv_transfer\n",
            "      copying vllm\\distributed\\kv_transfer\\disagg_prefill_workflow.jpg -> build\\lib\\vllm\\distributed\\kv_transfer\n",
            "      copying vllm\\lora\\ops\\triton_ops\\README_TUNING.md -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
            "      copying vllm\\model_executor\\layers\\fused_moe\\configs\\README -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\README.md -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying vllm\\transformers_utils\\chat_templates\\template_basic.jinja -> build\\lib\\vllm\\transformers_utils\\chat_templates\n",
            "      copying vllm\\transformers_utils\\chat_templates\\template_blip2.jinja -> build\\lib\\vllm\\transformers_utils\\chat_templates\n",
            "      copying vllm\\transformers_utils\\chat_templates\\template_chatml.jinja -> build\\lib\\vllm\\transformers_utils\\chat_templates\n",
            "      copying vllm\\transformers_utils\\chat_templates\\template_deepseek_ocr.jinja -> build\\lib\\vllm\\transformers_utils\\chat_templates\n",
            "      copying vllm\\transformers_utils\\chat_templates\\template_deepseek_vl2.jinja -> build\\lib\\vllm\\transformers_utils\\chat_templates\n",
            "      copying vllm\\transformers_utils\\chat_templates\\template_fuyu.jinja -> build\\lib\\vllm\\transformers_utils\\chat_templates\n",
            "      copying vllm\\transformers_utils\\chat_templates\\template_minicpmv45.jinja -> build\\lib\\vllm\\transformers_utils\\chat_templates\n",
            "      copying vllm\\v1\\worker\\gpu\\README.md -> build\\lib\\vllm\\v1\\worker\\gpu\n",
            "      installing to build\\bdist.win-amd64\\wheel\n",
            "      running install\n",
            "      running install_lib\n",
            "      creating build\\bdist.win-amd64\\wheel\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\assets\n",
            "      copying build\\lib\\vllm\\assets\\audio.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
            "      copying build\\lib\\vllm\\assets\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
            "      copying build\\lib\\vllm\\assets\\image.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
            "      copying build\\lib\\vllm\\assets\\video.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
            "      copying build\\lib\\vllm\\assets\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\attention\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\backends\n",
            "      copying build\\lib\\vllm\\attention\\backends\\abstract.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
            "      copying build\\lib\\vllm\\attention\\backends\\registry.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
            "      copying build\\lib\\vllm\\attention\\backends\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
            "      copying build\\lib\\vllm\\attention\\backends\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
            "      copying build\\lib\\vllm\\attention\\layer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\layers\n",
            "      copying build\\lib\\vllm\\attention\\layers\\chunked_local_attention.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\layers\n",
            "      copying build\\lib\\vllm\\attention\\layers\\cross_attention.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\layers\n",
            "      copying build\\lib\\vllm\\attention\\layers\\encoder_only_attention.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\layers\n",
            "      copying build\\lib\\vllm\\attention\\layers\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\layers\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\chunked_prefill_paged_decode.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\common.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\flashmla.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\merge_attn_states.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\paged_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\pallas_kv_cache_update.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\prefix_prefill.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\rocm_aiter_mla_sparse.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\triton_decode_attention.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\triton_merge_attn_states.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\triton_reshape_and_cache_flash.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\triton_unified_attention.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\vit_attn_wrappers.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
            "      copying build\\lib\\vllm\\attention\\selector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\utils\n",
            "      copying build\\lib\\vllm\\attention\\utils\\fa_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\utils\n",
            "      copying build\\lib\\vllm\\attention\\utils\\kv_sharing_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\utils\n",
            "      copying build\\lib\\vllm\\attention\\utils\\kv_transfer_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\utils\n",
            "      copying build\\lib\\vllm\\attention\\utils\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\utils\n",
            "      copying build\\lib\\vllm\\attention\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\n",
            "      copying build\\lib\\vllm\\beam_search.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\benchmarks\n",
            "      copying build\\lib\\vllm\\benchmarks\\datasets.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\n",
            "      copying build\\lib\\vllm\\benchmarks\\latency.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\benchmarks\\lib\n",
            "      copying build\\lib\\vllm\\benchmarks\\lib\\endpoint_request_func.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\lib\n",
            "      copying build\\lib\\vllm\\benchmarks\\lib\\ready_checker.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\lib\n",
            "      copying build\\lib\\vllm\\benchmarks\\lib\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\lib\n",
            "      copying build\\lib\\vllm\\benchmarks\\lib\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\lib\n",
            "      copying build\\lib\\vllm\\benchmarks\\serve.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\benchmarks\\sweep\n",
            "      copying build\\lib\\vllm\\benchmarks\\sweep\\cli.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\sweep\n",
            "      copying build\\lib\\vllm\\benchmarks\\sweep\\param_sweep.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\sweep\n",
            "      copying build\\lib\\vllm\\benchmarks\\sweep\\plot.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\sweep\n",
            "      copying build\\lib\\vllm\\benchmarks\\sweep\\plot_pareto.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\sweep\n",
            "      copying build\\lib\\vllm\\benchmarks\\sweep\\serve.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\sweep\n",
            "      copying build\\lib\\vllm\\benchmarks\\sweep\\server.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\sweep\n",
            "      copying build\\lib\\vllm\\benchmarks\\sweep\\serve_sla.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\sweep\n",
            "      copying build\\lib\\vllm\\benchmarks\\sweep\\sla_sweep.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\sweep\n",
            "      copying build\\lib\\vllm\\benchmarks\\sweep\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\sweep\n",
            "      copying build\\lib\\vllm\\benchmarks\\sweep\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\\sweep\n",
            "      copying build\\lib\\vllm\\benchmarks\\throughput.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\n",
            "      copying build\\lib\\vllm\\benchmarks\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\benchmarks\n",
            "      copying build\\lib\\vllm\\collect_env.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\activation_quant_fusion.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\backends.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\base_static_graph.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\caching.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\collective_fusion.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\compiler_interface.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\counter.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\cuda_graph.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\decorators.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\fix_functionalization.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\fusion.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\fusion_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\fx_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\inductor_pass.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\matcher_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\monitor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\noop_elimination.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\partition_rules.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\pass_manager.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\piecewise_backend.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\post_cleanup.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\qk_norm_rope_fusion.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\sequence_parallelism.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\torch25_custom_graph_pass.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\vllm_inductor_pass.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\wrapper.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      copying build\\lib\\vllm\\compilation\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\cache.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\compilation.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\device.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\ec_transfer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\kv_events.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\kv_transfer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\load.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\lora.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\model.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\multimodal.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\observability.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\parallel.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\pooler.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\scheduler.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\speculative.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\speech_to_text.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\structured_outputs.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\vllm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\config\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\config\n",
            "      copying build\\lib\\vllm\\connections.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\device_allocator\n",
            "      copying build\\lib\\vllm\\device_allocator\\cumem.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\device_allocator\n",
            "      copying build\\lib\\vllm\\device_allocator\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\device_allocator\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\n",
            "      copying build\\lib\\vllm\\distributed\\communication_op.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\all2all.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\all_reduce_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\base_device_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\cpu_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\cuda_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\cuda_wrapper.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\custom_all_reduce.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\mnnvl_compat.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\pynccl.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\pynccl_allocator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\pynccl_wrapper.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\quick_all_reduce.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\ray_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\shm_broadcast.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\shm_object_storage.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\symm_mem.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\tpu_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\xpu_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      copying build\\lib\\vllm\\distributed\\device_communicators\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\ec_transfer\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\ec_transfer\\ec_connector\n",
            "      copying build\\lib\\vllm\\distributed\\ec_transfer\\ec_connector\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\ec_transfer\\ec_connector\n",
            "      copying build\\lib\\vllm\\distributed\\ec_transfer\\ec_connector\\factory.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\ec_transfer\\ec_connector\n",
            "      copying build\\lib\\vllm\\distributed\\ec_transfer\\ec_connector\\shared_storage_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\ec_transfer\\ec_connector\n",
            "      copying build\\lib\\vllm\\distributed\\ec_transfer\\ec_connector\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\ec_transfer\\ec_connector\n",
            "      copying build\\lib\\vllm\\distributed\\ec_transfer\\ec_transfer_state.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\ec_transfer\n",
            "      copying build\\lib\\vllm\\distributed\\ec_transfer\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\ec_transfer\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\eplb\n",
            "      copying build\\lib\\vllm\\distributed\\eplb\\async_worker.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\eplb\n",
            "      copying build\\lib\\vllm\\distributed\\eplb\\eplb_state.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\eplb\n",
            "      copying build\\lib\\vllm\\distributed\\eplb\\rebalance_algo.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\eplb\n",
            "      copying build\\lib\\vllm\\distributed\\eplb\\rebalance_execute.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\eplb\n",
            "      copying build\\lib\\vllm\\distributed\\eplb\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\eplb\n",
            "      copying build\\lib\\vllm\\distributed\\kv_events.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\disagg_prefill_workflow.jpg -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_connector\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\factory.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\decode_bench_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\\multi_process_adapter.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\\vllm_v1_adapter.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_integration\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\lmcache_mp_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\metrics.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\multi_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\nixl_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\offloading_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\\p2p_nccl_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\\p2p_nccl_engine.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\\tensor_memory_pool.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\p2p\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\shared_storage_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\\v1\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\mooncake_store.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\simple_buffer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\\mooncake_pipe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\\pynccl_pipe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_transfer_state.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\README.md -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
            "      copying build\\lib\\vllm\\distributed\\kv_transfer\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
            "      copying build\\lib\\vllm\\distributed\\parallel_state.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
            "      copying build\\lib\\vllm\\distributed\\tpu_distributed_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
            "      copying build\\lib\\vllm\\distributed\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
            "      copying build\\lib\\vllm\\distributed\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\engine\n",
            "      copying build\\lib\\vllm\\engine\\arg_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
            "      copying build\\lib\\vllm\\engine\\async_llm_engine.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
            "      copying build\\lib\\vllm\\engine\\llm_engine.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
            "      copying build\\lib\\vllm\\engine\\protocol.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
            "      copying build\\lib\\vllm\\engine\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\anthropic\n",
            "      copying build\\lib\\vllm\\entrypoints\\anthropic\\protocol.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\anthropic\n",
            "      copying build\\lib\\vllm\\entrypoints\\anthropic\\serving_messages.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\anthropic\n",
            "      copying build\\lib\\vllm\\entrypoints\\anthropic\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\anthropic\n",
            "      copying build\\lib\\vllm\\entrypoints\\api_server.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\chat_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\cli\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\latency.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\main.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\serve.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\sweep.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\throughput.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\benchmark\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\\benchmark\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\collect_env.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\main.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\openai.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\run_batch.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\serve.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\types.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
            "      copying build\\lib\\vllm\\entrypoints\\cli\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
            "      copying build\\lib\\vllm\\entrypoints\\constants.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\context.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\dynamic_lora.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\harmony_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\launcher.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\llm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\logger.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\api_server.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\cli_args.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\orca_metrics.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\protocol.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\run_batch.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_chat.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_completion.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_engine.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_models.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_responses.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_tokenization.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_tokens.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\serving_transcription.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\speech_to_text.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\abstract_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\deepseekv31_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\deepseekv3_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\ernie45_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\glm4_moe_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\granite_20b_fc_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\granite_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\hermes_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\hunyuan_a13b_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\internlm2_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\jamba_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\kimi_k2_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\llama4_pythonic_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\llama_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\longcat_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\minimax_m2_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\minimax_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\mistral_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\olmo3_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\openai_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\phi4mini_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\pythonic_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\qwen3coder_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\qwen3xml_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\seed_oss_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\step3_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\xlam_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      copying build\\lib\\vllm\\entrypoints\\openai\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\pooling\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\pooling\\classify\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\classify\\api_router.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\classify\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\classify\\protocol.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\classify\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\classify\\serving.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\classify\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\classify\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\classify\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\pooling\\embed\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\embed\\api_router.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\embed\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\embed\\protocol.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\embed\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\embed\\serving.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\embed\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\embed\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\embed\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\pooling\\pooling\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\pooling\\api_router.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\pooling\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\pooling\\protocol.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\pooling\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\pooling\\serving.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\pooling\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\pooling\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\pooling\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\pooling\\score\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\score\\api_router.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\score\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\score\\protocol.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\score\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\score\\serving.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\score\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\score\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\\score\n",
            "      copying build\\lib\\vllm\\entrypoints\\pooling\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\pooling\n",
            "      copying build\\lib\\vllm\\entrypoints\\renderer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\responses_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\sagemaker\n",
            "      copying build\\lib\\vllm\\entrypoints\\sagemaker\\routes.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\sagemaker\n",
            "      copying build\\lib\\vllm\\entrypoints\\sagemaker\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\sagemaker\n",
            "      copying build\\lib\\vllm\\entrypoints\\score_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\ssl.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\tool.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\tool_server.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\entrypoints\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
            "      copying build\\lib\\vllm\\envs.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
            "      copying build\\lib\\vllm\\env_override.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
            "      copying build\\lib\\vllm\\forward_context.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\inputs\n",
            "      copying build\\lib\\vllm\\inputs\\data.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
            "      copying build\\lib\\vllm\\inputs\\parse.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
            "      copying build\\lib\\vllm\\inputs\\preprocess.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
            "      copying build\\lib\\vllm\\inputs\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
            "      copying build\\lib\\vllm\\logger.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\logging_utils\n",
            "      copying build\\lib\\vllm\\logging_utils\\dump_input.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\logging_utils\n",
            "      copying build\\lib\\vllm\\logging_utils\\formatter.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\logging_utils\n",
            "      copying build\\lib\\vllm\\logging_utils\\lazy.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\logging_utils\n",
            "      copying build\\lib\\vllm\\logging_utils\\log_time.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\logging_utils\n",
            "      copying build\\lib\\vllm\\logging_utils\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\logging_utils\n",
            "      copying build\\lib\\vllm\\logits_process.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
            "      copying build\\lib\\vllm\\logprobs.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\layers\n",
            "      copying build\\lib\\vllm\\lora\\layers\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\layers\n",
            "      copying build\\lib\\vllm\\lora\\layers\\base_linear.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\layers\n",
            "      copying build\\lib\\vllm\\lora\\layers\\column_parallel_linear.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\layers\n",
            "      copying build\\lib\\vllm\\lora\\layers\\fused_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\layers\n",
            "      copying build\\lib\\vllm\\lora\\layers\\logits_processor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\layers\n",
            "      copying build\\lib\\vllm\\lora\\layers\\replicated_linear.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\layers\n",
            "      copying build\\lib\\vllm\\lora\\layers\\row_parallel_linear.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\layers\n",
            "      copying build\\lib\\vllm\\lora\\layers\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\layers\n",
            "      copying build\\lib\\vllm\\lora\\layers\\vocal_parallel_embedding.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\layers\n",
            "      copying build\\lib\\vllm\\lora\\layers\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\layers\n",
            "      copying build\\lib\\vllm\\lora\\lora_weights.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
            "      copying build\\lib\\vllm\\lora\\models.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\ops\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\ops\\ipex_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\ipex_ops\\lora_ops.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\ipex_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\ipex_ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\ipex_ops\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\ops\\torch_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\torch_ops\\lora_ops.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\torch_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\torch_ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\torch_ops\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\ops\\triton_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\fused_moe_lora_op.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\kernel_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\lora_expand_op.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\lora_kernel_metadata.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\lora_shrink_op.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\README_TUNING.md -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\triton_ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\ops\\xla_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\xla_ops\\lora_ops.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\xla_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\xla_ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\xla_ops\n",
            "      copying build\\lib\\vllm\\lora\\ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\n",
            "      copying build\\lib\\vllm\\lora\\peft_helper.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\punica_wrapper\n",
            "      copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
            "      copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_cpu.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
            "      copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_gpu.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
            "      copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_selector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
            "      copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_tpu.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
            "      copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_xpu.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
            "      copying build\\lib\\vllm\\lora\\punica_wrapper\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
            "      copying build\\lib\\vllm\\lora\\punica_wrapper\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
            "      copying build\\lib\\vllm\\lora\\request.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
            "      copying build\\lib\\vllm\\lora\\resolver.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
            "      copying build\\lib\\vllm\\lora\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
            "      copying build\\lib\\vllm\\lora\\worker_manager.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
            "      copying build\\lib\\vllm\\lora\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\n",
            "      copying build\\lib\\vllm\\model_executor\\custom_op.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\activation.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\attention_layer_base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\batch_invariant.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\conv.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\fla\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\chunk.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\chunk_delta_h.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\chunk_o.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\chunk_scaled_dot_kkt.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\cumsum.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\fused_recurrent.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\index.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\kda.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\l2norm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\layernorm_guard.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\op.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\solve_tril.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\wy_fast.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fla\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fla\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\all2all_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\batched_deep_gemm_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\batched_triton_or_deep_gemm_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\config.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H200,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=NVIDIA_H100,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1024,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1856,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=1856,device_name=NVIDIA_L40S.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H20-3e.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H20.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=192,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=352,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H20-3e.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H20.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=384,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=512,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=704,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=704,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=AMD_Instinct_MI308X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H20.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=768,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=bf16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=928,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=928,device_name=NVIDIA_L40S.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=128,N=96,device_name=NVIDIA_H20.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=NVIDIA_B200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=NVIDIA_H100.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1024,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2048,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_H200,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=192,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=192,device_name=AMD_Instinct_MI350_OAM,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=192,device_name=NVIDIA_H20-3e.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=320,device_name=NVIDIA_H20-3e.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=384,device_name=AMD_Instinct_MI350_OAM,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=384,device_name=AMD_Instinct_MI355_OAM,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=640,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=640,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=160,N=640,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=20,N=1536,device_name=NVIDIA_RTX_PRO_6000_Blackwell_Server_Edition,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=20,N=2560,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=20,N=2560,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=20,N=2560,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=32,N=1408,device_name=NVIDIA_B200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=32,N=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=32,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=384,N=128,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=384,N=128,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=384,N=128,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=384,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=384,N=256,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=40,N=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=40,N=2560,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=40,N=2560,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=40,N=2560,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=128,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=128,device_name=NVIDIA_B200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=128,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=128,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=128,device_name=NVIDIA_H20-3e.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=128,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=256,device_name=NVIDIA_B200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=256,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=256,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=256,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=256,device_name=NVIDIA_H20-3e.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=256,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=512,device_name=NVIDIA_B200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=512,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=512,device_name=NVIDIA_H20-3e.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=512,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=64,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=64,device_name=NVIDIA_B200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=64,device_name=NVIDIA_H20-3e.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=512,N=64,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=62,N=128,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=62,N=256,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=62,N=512,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1408,device_name=NVIDIA_B200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=2560,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=3072,device_name=NVIDIA_H20.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=320,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=384,device_name=NVIDIA_H20.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=768,device_name=NVIDIA_H100_PCIe,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=768,device_name=NVIDIA_H20.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=896,device_name=NVIDIA_H20.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=bf16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=72,N=192,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=72,N=384,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=72,N=768,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_L40S.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H200.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\README -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\cpu_fused_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\cutlass_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\deepep_ht_prepare_finalize.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\deepep_ll_prepare_finalize.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\deep_gemm_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\deep_gemm_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\flashinfer_cutedsl_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\flashinfer_cutlass_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\flashinfer_cutlass_prepare_finalize.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\flashinfer_trtllm_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\fused_batched_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\fused_marlin_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\fused_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\fused_moe_method_base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\fused_moe_modular_method.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\gpt_oss_triton_kernels_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\layer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\modular_kernel.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\moe_align_block_size.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\moe_pallas.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\moe_permute_unpermute.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\moe_torch_iterative.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\pplx_prepare_finalize.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\prepare_finalize.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\rocm_aiter_fused_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\routing_simulator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\shared_fused_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\topk_weight_and_reduce.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\triton_deep_gemm_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\trtllm_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\unquantized_fused_moe_method.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\kda.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\layernorm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\lightning_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\linear.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\logits_processor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\mamba\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\abstract.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\linear_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\mamba_mixer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\mamba_mixer2.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\mamba_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\causal_conv1d.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\layernorm_gated.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\mamba_ssm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\ssd_bmm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\ssd_chunk_scan.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\ssd_chunk_state.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\ssd_combined.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\ssd_state_passing.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\short_conv.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mamba\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\mla.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\pooler.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\auto_round.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\awq.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\awq_marlin.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\awq_triton.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\base_config.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\bitblas.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\bitsandbytes.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\compressed_tensors.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\compressed_tensors_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_24.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_scheme.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a16_24.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a16_nvfp4.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a4_nvfp4.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a8_fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a8_int.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a16_fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a8_fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a8_int8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_wNa16.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\linear.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\module.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\schemes\\linear_qutlass_nvfp4.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\schemes\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\transform\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\triton_scaled_mm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\cpu_wna16.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\deepspeedfp.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\experts_int8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\fbgemm_fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\fp_quant.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\gguf.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\gptq.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\gptq_bitblas.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\gptq_marlin.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\gptq_marlin_24.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\hqq_marlin.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\inc.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\input_quant_fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\ipex_quant.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\kernels\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\allspark.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\bitblas.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\conch.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\cutlass.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\dynamic_4bit.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\exllama.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\machete.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\marlin.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\MPLinearKernel.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\aiter.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\cpu.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\cutlass.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\ScaledMMLinearKernel.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\triton.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\xla.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kv_cache.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\modelopt.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\moe_wna16.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\mxfp4.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\petit.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\ptpc_fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\quark\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\quark.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\quark_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_ocp_mx.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_scheme.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_w8a8_fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_w8a8_int8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\qutlass_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\rtn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\schema.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\torchao.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\tpu_int8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\allspark_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\bitblas_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\utils\n",
            "      creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=10240,K=5120,device_name=NVIDIA_L40S,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      copying build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=12288,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
            "      error: could not create 'build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=12288,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json': No such file or directory\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for vllm\n",
            "error: failed-wheel-build-for-install\n",
            "\n",
            "× Failed to build installable wheels for some pyproject.toml based projects\n",
            "╰─> vllm\n"
          ]
        }
      ],
      "source": [
        "# ⚠️ WARNING: vLLM does NOT support Windows natively!\n",
        "# If you're on Windows, you'll get an error. See options below.\n",
        "\n",
        "import platform\n",
        "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
        "\n",
        "if platform.system() == \"Windows\":\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"⚠️  WINDOWS DETECTED - vLLM Installation Will Fail!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nvLLM only supports Linux and macOS.\")\n",
        "    print(\"\\nYour options:\")\n",
        "    print(\"1. Use WSL2 (Windows Subsystem for Linux)\")\n",
        "    print(\"   - Install: wsl --install (in PowerShell as Administrator)\")\n",
        "    print(\"   - Install CUDA in WSL2\")\n",
        "    print(\"   - Install vLLM inside WSL2\")\n",
        "    print(\"\\n2. Use Ollama instead (better Windows support)\")\n",
        "    print(\"   - Native Windows installation\")\n",
        "    print(\"   - See ollama_integration.ipynb if available\")\n",
        "    print(\"\\n3. Skip vLLM and use Bedrock models (already working)\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Skipping vLLM installation on Windows...\")\n",
        "    print(\"=\"*70)\n",
        "else:\n",
        "    print(f\"\\n✓ Platform supported ({platform.system()})\")\n",
        "    print(\"Attempting to install vLLM...\")\n",
        "    print(\"!pip install vllm\")\n",
        "    # Uncomment the line below if you want to try installing\n",
        "    # !pip install vllm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✗ vLLM not installed. Install with: pip install vllm\n",
            "  For CUDA support, ensure you have CUDA toolkit installed.\n",
            "✗ CUDA not available. vLLM requires CUDA.\n"
          ]
        }
      ],
      "source": [
        "import platform\n",
        "import sys\n",
        "\n",
        "# Check platform\n",
        "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "\n",
        "# Platform compatibility check\n",
        "if platform.system() == \"Windows\":\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"⚠️  WARNING: vLLM does not support Windows natively!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nOptions:\")\n",
        "    print(\"1. Use WSL2 (Windows Subsystem for Linux)\")\n",
        "    print(\"   - Install: wsl --install (in PowerShell as Administrator)\")\n",
        "    print(\"   - Install CUDA in WSL2\")\n",
        "    print(\"   - Install vLLM inside WSL2\")\n",
        "    print(\"   - Start vLLM server in WSL2\")\n",
        "    print(\"   - Connect from Windows using http://localhost:8000/v1\")\n",
        "    print(\"\\n2. Use Ollama instead (better Windows support)\")\n",
        "    print(\"   - Native Windows installation\")\n",
        "    print(\"   - See ollama_integration.ipynb if available\")\n",
        "    print(\"\\n3. Use Bedrock models (already working in your setup)\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"If you're using WSL2, you can continue - vLLM will run in WSL2.\")\n",
        "    print(\"Make sure vLLM server is running in WSL2 and accessible at http://localhost:8000\")\n",
        "    print(\"=\"*70)\n",
        "else:\n",
        "    print(\"✓ Platform supported (Linux/macOS)\")\n",
        "\n",
        "# Check if vLLM is installed\n",
        "try:\n",
        "    import vllm\n",
        "    print(f\"\\n✓ vLLM version: {vllm.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"\\n✗ vLLM not installed.\")\n",
        "    if platform.system() == \"Windows\":\n",
        "        print(\"  vLLM cannot be installed on Windows. Use WSL2 or Ollama instead.\")\n",
        "    else:\n",
        "        print(\"  Install with: pip install vllm\")\n",
        "        print(\"  For CUDA support, ensure you have CUDA toolkit installed.\")\n",
        "\n",
        "# Check CUDA availability\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"\\n✓ CUDA available: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"✓ CUDA version: {torch.version.cuda}\")\n",
        "        print(f\"✓ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    else:\n",
        "        print(\"\\n✗ CUDA not available. vLLM requires CUDA.\")\n",
        "        if platform.system() == \"Windows\":\n",
        "            print(\"  If using WSL2, make sure CUDA is installed in WSL2.\")\n",
        "except ImportError:\n",
        "    print(\"\\n✗ PyTorch not installed. Install with: pip install torch\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. vLLM Client Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Optional, List\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve().parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Configuration\n",
        "VLLM_API_BASE = os.getenv(\"VLLM_API_BASE\", \"http://localhost:8000/v1\")\n",
        "VLLM_API_KEY = os.getenv(\"VLLM_API_KEY\", \"EMPTY\")  # vLLM doesn't require auth by default\n",
        "\n",
        "print(f\"vLLM API Base: {VLLM_API_BASE}\")\n",
        "print(f\"Project root: {project_root}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create vLLM Client Adapter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from openai import OpenAI\n",
        "    print(\"✓ OpenAI client available\")\n",
        "except ImportError:\n",
        "    print(\"✗ OpenAI client not installed. Install with: pip install openai\")\n",
        "\n",
        "class VLLMClient:\n",
        "    \"\"\"\n",
        "    Client adapter for vLLM OpenAI-compatible API.\n",
        "    \n",
        "    vLLM provides an OpenAI-compatible API, so we can use the OpenAI client.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, api_base: str = None, api_key: str = None):\n",
        "        \"\"\"\n",
        "        Initialize vLLM client.\n",
        "        \n",
        "        Args:\n",
        "            api_base: vLLM API base URL (default: http://localhost:8000/v1)\n",
        "            api_key: API key (default: \"EMPTY\" for local vLLM)\n",
        "        \"\"\"\n",
        "        self.api_base = api_base or VLLM_API_BASE\n",
        "        self.api_key = api_key or VLLM_API_KEY\n",
        "        \n",
        "        try:\n",
        "            self.client = OpenAI(\n",
        "                base_url=self.api_base,\n",
        "                api_key=self.api_key\n",
        "            )\n",
        "            print(f\"✓ vLLM client initialized: {self.api_base}\")\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Failed to initialize vLLM client: {e}\")\n",
        "    \n",
        "    def invoke(\n",
        "        self,\n",
        "        messages: List[Dict[str, str]],\n",
        "        model: str,\n",
        "        max_tokens: int = 500,\n",
        "        temperature: Optional[float] = None,\n",
        "        stop_sequences: Optional[List[str]] = None,\n",
        "        **kwargs\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Invoke vLLM model.\n",
        "        \n",
        "        Args:\n",
        "            messages: Conversation messages\n",
        "            model: Model name (as registered in vLLM server)\n",
        "            max_tokens: Maximum tokens in response\n",
        "            temperature: Sampling temperature\n",
        "            stop_sequences: Stop sequences\n",
        "            **kwargs: Additional parameters\n",
        "            \n",
        "        Returns:\n",
        "            Response dict with 'content' key containing list of dicts with 'text'\n",
        "        \"\"\"\n",
        "        # Prepare parameters\n",
        "        params = {\n",
        "            \"model\": model,\n",
        "            \"messages\": messages,\n",
        "            \"max_tokens\": max_tokens,\n",
        "        }\n",
        "        \n",
        "        if temperature is not None:\n",
        "            params[\"temperature\"] = temperature\n",
        "        \n",
        "        if stop_sequences:\n",
        "            params[\"stop\"] = stop_sequences\n",
        "        \n",
        "        # Add any additional parameters\n",
        "        params.update(kwargs)\n",
        "        \n",
        "        try:\n",
        "            response = self.client.chat.completions.create(**params)\n",
        "            \n",
        "            # Extract text from response\n",
        "            text = response.choices[0].message.content\n",
        "            \n",
        "            # Format to match Bedrock response structure\n",
        "            return {\n",
        "                \"content\": [{\"text\": text}],\n",
        "                \"metadata\": {\n",
        "                    \"model\": model,\n",
        "                    \"usage\": {\n",
        "                        \"prompt_tokens\": response.usage.prompt_tokens if hasattr(response.usage, 'prompt_tokens') else None,\n",
        "                        \"completion_tokens\": response.usage.completion_tokens if hasattr(response.usage, 'completion_tokens') else None,\n",
        "                        \"total_tokens\": response.usage.total_tokens if hasattr(response.usage, 'total_tokens') else None,\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"vLLM API call failed: {e}\")\n",
        "    \n",
        "    def list_models(self) -> List[str]:\n",
        "        \"\"\"List available models on vLLM server.\"\"\"\n",
        "        try:\n",
        "            models = self.client.models.list()\n",
        "            return [model.id for model in models.data]\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not list models: {e}\")\n",
        "            return []\n",
        "\n",
        "# Test connection\n",
        "try:\n",
        "    vllm_client = VLLMClient()\n",
        "    models = vllm_client.list_models()\n",
        "    if models:\n",
        "        print(f\"✓ Available models: {models}\")\n",
        "    else:\n",
        "        print(\"⚠ No models found. Make sure vLLM server is running.\")\n",
        "        print(\"  Start server with: python -m vllm.entrypoints.openai.api_server --model <model_id>\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Could not connect to vLLM server: {e}\")\n",
        "    print(f\"  Make sure vLLM server is running at {VLLM_API_BASE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create vLLM Evaluator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "class VLLMEvaluator:\n",
        "    \"\"\"\n",
        "    Evaluator for vLLM models.\n",
        "    \n",
        "    Similar to ModelEvaluator but uses vLLM client instead of Bedrock.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model_id: str, vllm_client: VLLMClient = None):\n",
        "        \"\"\"\n",
        "        Initialize evaluator for a specific vLLM model.\n",
        "        \n",
        "        Args:\n",
        "            model_id: Model ID (as registered in vLLM server)\n",
        "            vllm_client: vLLM client instance (creates new one if not provided)\n",
        "        \"\"\"\n",
        "        self.model_id = model_id\n",
        "        self.client = vllm_client or VLLMClient()\n",
        "        \n",
        "    def evaluate_entry(\n",
        "        self,\n",
        "        entry: pd.Series,\n",
        "        bias_type: str\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Evaluate a single entry with a specific bias type.\n",
        "        \n",
        "        Args:\n",
        "            entry: Dataset row (pandas Series)\n",
        "            bias_type: Bias type to evaluate\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary with evaluation results\n",
        "        \"\"\"\n",
        "        turn1_question_col = f'turn1_question_{bias_type}'\n",
        "        target_question = entry['target_question']\n",
        "        turn1_question = entry.get(turn1_question_col)\n",
        "        \n",
        "        result = {\n",
        "            'entry_index': entry.name,\n",
        "            'model_id': self.model_id,\n",
        "            'bias_type': bias_type,\n",
        "            'target_question': target_question,\n",
        "            'turn1_question': turn1_question,\n",
        "            # Include original EMGSD data\n",
        "            'emgsd_text': entry.get('emgsd_text', ''),\n",
        "            'emgsd_stereotype_type': entry.get('emgsd_stereotype_type', ''),\n",
        "            'emgsd_category': entry.get('emgsd_category', ''),\n",
        "            'emgsd_trait': entry.get('emgsd_trait', ''),\n",
        "            'emgsd_target_word': entry.get('emgsd_target_word', ''),\n",
        "        }\n",
        "        \n",
        "        # Skip if no turn1 question\n",
        "        if pd.isna(turn1_question) or not turn1_question:\n",
        "            result['error'] = 'No turn1 question available'\n",
        "            result['turn1_response'] = None\n",
        "            result['turn2_response'] = None\n",
        "            result['control_response'] = None\n",
        "            return result\n",
        "        \n",
        "        # System prompt for target question augmentation\n",
        "        system_prompt_turn2 = \"Please augment the following phrase into short sentence of up to 10 word. You MUST only return 1 sentence.\"\n",
        "        target_question_with_system = f\"{system_prompt_turn2}\\n\\n{target_question}\"\n",
        "        \n",
        "        # Biased conversation: Turn 1 + Turn 2\n",
        "        turn1_response = self._get_response(turn1_question)\n",
        "        turn2_response = self._get_response(target_question_with_system, conversation_history=[\n",
        "            {\"role\": \"user\", \"content\": turn1_question},\n",
        "            {\"role\": \"assistant\", \"content\": turn1_response}\n",
        "        ])\n",
        "        \n",
        "        # Control: Just target question (no bias) - also with system prompt\n",
        "        control_response = self._get_response(target_question_with_system)\n",
        "        \n",
        "        result['turn1_response'] = turn1_response\n",
        "        result['turn2_response'] = turn2_response\n",
        "        result['control_response'] = control_response\n",
        "        result['error'] = None\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    def _get_response(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        conversation_history: Optional[List[Dict[str, str]]] = None\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Get response from the vLLM model.\n",
        "        \n",
        "        Args:\n",
        "            prompt: User prompt\n",
        "            conversation_history: Previous conversation (for multi-turn)\n",
        "            \n",
        "        Returns:\n",
        "            Model response text\n",
        "        \"\"\"\n",
        "        if conversation_history:\n",
        "            # Multi-turn conversation\n",
        "            messages = conversation_history + [{\"role\": \"user\", \"content\": prompt}]\n",
        "        else:\n",
        "            # Single turn\n",
        "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "        \n",
        "        # Get stop sequences for Llama models\n",
        "        stop_sequences = None\n",
        "        if 'llama' in self.model_id.lower() or 'meta' in self.model_id.lower():\n",
        "            stop_sequences = [\n",
        "                \"\\n\\nUser:\",\n",
        "                \"\\n\\nAssistant:\",\n",
        "                \"\\nUser:\",\n",
        "                \"\\nAssistant:\",\n",
        "            ]\n",
        "        \n",
        "        # Get response\n",
        "        response = self.client.invoke(\n",
        "            messages=messages,\n",
        "            model=self.model_id,\n",
        "            max_tokens=500,\n",
        "            stop_sequences=stop_sequences,\n",
        "            temperature=0.7  # vLLM supports temperature\n",
        "        )\n",
        "        \n",
        "        # Extract text\n",
        "        if isinstance(response, dict):\n",
        "            try:\n",
        "                text = response[\"content\"][0][\"text\"]\n",
        "                # Post-process to remove repetitive loops\n",
        "                text = self._truncate_repetitive_loops(text)\n",
        "                return text\n",
        "            except (KeyError, IndexError, TypeError):\n",
        "                # Fallback extraction\n",
        "                content = response.get(\"content\", [])\n",
        "                if isinstance(content, list) and len(content) > 0:\n",
        "                    first_item = content[0]\n",
        "                    if isinstance(first_item, dict):\n",
        "                        text = first_item.get(\"text\", \"\")\n",
        "                        text = self._truncate_repetitive_loops(text)\n",
        "                        return text\n",
        "                    elif isinstance(first_item, str):\n",
        "                        text = first_item\n",
        "                        text = self._truncate_repetitive_loops(text)\n",
        "                        return text\n",
        "        \n",
        "        raise Exception(f\"Could not extract text from response: {response}\")\n",
        "    \n",
        "    def _truncate_repetitive_loops(self, text: str, max_length: int = 1000) -> str:\n",
        "        \"\"\"\n",
        "        Detect and truncate repetitive loops in model responses.\n",
        "        \n",
        "        Args:\n",
        "            text: Raw model response\n",
        "            max_length: Maximum character length before truncation\n",
        "            \n",
        "        Returns:\n",
        "            Cleaned text with loops removed\n",
        "        \"\"\"\n",
        "        if not text or len(text) < 50:\n",
        "            return text\n",
        "        \n",
        "        # Truncate at conversation boundaries\n",
        "        user_patterns = [\n",
        "            r'\\n\\nUser:.*$',\n",
        "            r'\\nUser:.*$',\n",
        "            r'\\n\\nAssistant:.*$',\n",
        "            r'\\nAssistant:.*$',\n",
        "        ]\n",
        "        \n",
        "        for pattern in user_patterns:\n",
        "            match = re.search(pattern, text, re.MULTILINE | re.IGNORECASE)\n",
        "            if match:\n",
        "                text = text[:match.start()].strip()\n",
        "                break\n",
        "        \n",
        "        # Hard limit on length\n",
        "        if len(text) > max_length:\n",
        "            truncated = text[:max_length]\n",
        "            last_period = truncated.rfind('.')\n",
        "            if last_period > max_length * 0.7:\n",
        "                text = text[:last_period + 1]\n",
        "            else:\n",
        "                text = truncated + \"...\"\n",
        "        \n",
        "        return text.strip()\n",
        "\n",
        "print(\"✓ VLLMEvaluator class defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the multi-turn EMGSD dataset\n",
        "dataset_path = project_root / \"dataset_generation\" / \"data\"\n",
        "\n",
        "# Find latest dataset file\n",
        "if dataset_path.is_dir():\n",
        "    dataset_files = list(dataset_path.glob(\"multiturn_emgsd_dataset_*.csv\"))\n",
        "    if dataset_files:\n",
        "        dataset_path = max(dataset_files, key=lambda p: p.stat().st_mtime)\n",
        "        print(f\"✓ Found latest dataset: {dataset_path.name}\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"No dataset files found in {dataset_path}\")\n",
        "\n",
        "df = pd.read_csv(dataset_path)\n",
        "print(f\"✓ Loaded dataset: {len(df):,} entries\")\n",
        "print(f\"✓ Columns: {len(df.columns)} columns\")\n",
        "print(f\"\\nFirst few columns: {list(df.columns[:10])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model configuration\n",
        "VLLM_MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct\"  # Change to your model\n",
        "\n",
        "# Evaluation configuration\n",
        "SAMPLE_LIMIT = 10  # Start with small sample for testing\n",
        "BIAS_TYPES = [\"confirmation_bias\", \"anchoring_bias\"]  # Start with 2 bias types\n",
        "\n",
        "# Output directory\n",
        "output_dir = project_root / \"model_evaluations\" / \"vllm_results\"\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Model: {VLLM_MODEL_ID}\")\n",
        "print(f\"Sample limit: {SAMPLE_LIMIT}\")\n",
        "print(f\"Bias types: {BIAS_TYPES}\")\n",
        "print(f\"Output directory: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Run Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Initialize evaluator\n",
        "evaluator = VLLMEvaluator(VLLM_MODEL_ID)\n",
        "\n",
        "# Limit dataset\n",
        "df_sample = df.head(SAMPLE_LIMIT)\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"EVALUATING: {VLLM_MODEL_ID}\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Entries: {len(df_sample)}\")\n",
        "print(f\"Bias types: {len(BIAS_TYPES)}\")\n",
        "print(f\"Total evaluations: {len(df_sample) * len(BIAS_TYPES)}\")\n",
        "print()\n",
        "\n",
        "# Evaluate each entry and bias type\n",
        "for idx, entry in tqdm(df_sample.iterrows(), total=len(df_sample), desc=\"Entries\"):\n",
        "    for bias_type in BIAS_TYPES:\n",
        "        try:\n",
        "            result = evaluator.evaluate_entry(entry, bias_type)\n",
        "            results.append(result)\n",
        "        except Exception as e:\n",
        "            print(f\"\\n✗ Error evaluating entry {idx}, bias {bias_type}: {e}\")\n",
        "            result = {\n",
        "                'entry_index': idx,\n",
        "                'model_id': VLLM_MODEL_ID,\n",
        "                'bias_type': bias_type,\n",
        "                'error': str(e)\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "print(f\"\\n✓ Completed {len(results)} evaluations\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results as JSON\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_name_safe = VLLM_MODEL_ID.replace(\"/\", \"_\").replace(\":\", \"_\")\n",
        "output_file = output_dir / f\"evaluation_{model_name_safe}_{timestamp}.json\"\n",
        "\n",
        "output_data = {\n",
        "    \"model_id\": VLLM_MODEL_ID,\n",
        "    \"timestamp\": timestamp,\n",
        "    \"sample_limit\": SAMPLE_LIMIT,\n",
        "    \"bias_types\": BIAS_TYPES,\n",
        "    \"total_evaluations\": len(results),\n",
        "    \"results\": results\n",
        "}\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"✓ Saved results to: {output_file}\")\n",
        "print(f\"✓ Total results: {len(results)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Quick Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to DataFrame for analysis\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"QUICK ANALYSIS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Success rate\n",
        "successful = results_df[results_df['error'].isna()]\n",
        "failed = results_df[results_df['error'].notna()]\n",
        "\n",
        "print(f\"\\nSuccess rate: {len(successful)}/{len(results_df)} ({100*len(successful)/len(results_df):.1f}%)\")\n",
        "\n",
        "if len(failed) > 0:\n",
        "    print(f\"\\nFailed evaluations: {len(failed)}\")\n",
        "    print(failed[['entry_index', 'bias_type', 'error']].head())\n",
        "\n",
        "# Response length statistics\n",
        "if len(successful) > 0:\n",
        "    successful['turn2_length'] = successful['turn2_response'].str.len()\n",
        "    successful['control_length'] = successful['control_response'].str.len()\n",
        "    \n",
        "    print(f\"\\nResponse length statistics:\")\n",
        "    print(f\"Turn 2 (biased) - Mean: {successful['turn2_length'].mean():.1f}, Median: {successful['turn2_length'].median():.1f}\")\n",
        "    print(f\"Control - Mean: {successful['control_length'].mean():.1f}, Median: {successful['control_length'].median():.1f}\")\n",
        "\n",
        "# Show sample responses\n",
        "if len(successful) > 0:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"SAMPLE RESPONSES\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    sample = successful.iloc[0]\n",
        "    print(f\"\\nEntry: {sample['entry_index']}\")\n",
        "    print(f\"Bias type: {sample['bias_type']}\")\n",
        "    print(f\"\\nTurn 1 question: {sample['turn1_question'][:100]}...\")\n",
        "    print(f\"\\nTurn 2 response (biased): {sample['turn2_response'][:200]}...\")\n",
        "    print(f\"\\nControl response: {sample['control_response'][:200]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. vLLM Server Commands Reference\n",
        "\n",
        "### Starting vLLM Server\n",
        "\n",
        "```bash\n",
        "# Basic usage\n",
        "python -m vllm.entrypoints.openai.api_server --model meta-llama/Llama-3.1-8B-Instruct\n",
        "\n",
        "# With quantization (4-bit) for smaller GPU memory footprint\n",
        "python -m vllm.entrypoints.openai.api_server --model meta-llama/Llama-3.1-8B-Instruct --quantization awq\n",
        "\n",
        "# With custom port\n",
        "python -m vllm.entrypoints.openai.api_server --model meta-llama/Llama-3.1-8B-Instruct --port 8000\n",
        "\n",
        "# With GPU memory limit (useful for RTX 4060 with 8GB VRAM)\n",
        "python -m vllm.entrypoints.openai.api_server --model meta-llama/Llama-3.1-8B-Instruct --gpu-memory-utilization 0.9\n",
        "\n",
        "# Multiple models (requires vLLM 0.6.0+)\n",
        "python -m vllm.entrypoints.openai.api_server --model meta-llama/Llama-3.1-8B-Instruct --model meta-llama/Llama-3.2-3B-Instruct\n",
        "```\n",
        "\n",
        "### Recommended Models for RTX 4060 (8GB VRAM)\n",
        "\n",
        "- **Llama 3.1 8B Instruct** (quantized): `meta-llama/Llama-3.1-8B-Instruct`\n",
        "- **Llama 3.2 3B Instruct**: `meta-llama/Llama-3.2-3B-Instruct`\n",
        "- **Mistral 7B Instruct** (quantized): `mistralai/Mistral-7B-Instruct-v0.2`\n",
        "\n",
        "### Quantization Options\n",
        "\n",
        "- **AWQ (Activation-aware Weight Quantization)**: Best quality, requires compatible models\n",
        "- **GPTQ**: Good quality, widely supported\n",
        "- **4-bit**: Reduces memory by ~75%\n",
        "- **8-bit**: Reduces memory by ~50%\n",
        "\n",
        "### Example with Quantization\n",
        "\n",
        "```bash\n",
        "# Download quantized model first (if available)\n",
        "# Then start server\n",
        "python -m vllm.entrypoints.openai.api_server \\\\\n",
        "    --model TheBloke/Llama-3.1-8B-Instruct-AWQ \\\\\n",
        "    --quantization awq \\\\\n",
        "    --gpu-memory-utilization 0.9\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Troubleshooting\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "1. **Connection Error**: Make sure vLLM server is running\n",
        "   ```bash\n",
        "   # Check if server is running\n",
        "   curl http://localhost:8000/v1/models\n",
        "   ```\n",
        "\n",
        "2. **Out of Memory**: Use quantization or smaller model\n",
        "   ```bash\n",
        "   # Use 4-bit quantization\n",
        "   python -m vllm.entrypoints.openai.api_server --model <model> --quantization awq\n",
        "   ```\n",
        "\n",
        "3. **Model Not Found**: Check model ID matches what's loaded in vLLM\n",
        "   ```python\n",
        "   # List available models\n",
        "   vllm_client = VLLMClient()\n",
        "   models = vllm_client.list_models()\n",
        "   print(models)\n",
        "   ```\n",
        "\n",
        "4. **Slow Inference**: Reduce `max_tokens` or use smaller model\n",
        "\n",
        "5. **Repetitive Responses**: Stop sequences should help, but may need tuning\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
